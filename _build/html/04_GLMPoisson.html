

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Modelos Lineales Generalizados (GLM) para Poisson &#8212; Análisis Geoespacial</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '04_GLMPoisson';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Procesos Log-Gaussian Cox" href="05_LGCP.html" />
    <link rel="prev" title="Patrón de puntos" href="03_PointPattern.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Análisis Geoespacial - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Análisis Geoespacial - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    <no title>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00_Ambiente.html">Ambiente computacional</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_DatosEspaciales.html">Análisis Geoespacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_Mapping.html">El arte de hacer mapas</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_PointPattern.html">Patrón de puntos</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Modelos Lineales Generalizados (GLM) para Poisson</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_LGCP.html">Procesos Log-Gaussian Cox</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_Coropleta.html">Visualización de datos areales</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_MatrizCorrelacion.html">Autocorrelación espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_ClusterEspacial.html">Cluster espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_SpatialRegression.html">Regresión Espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_Heterogeneidad.html">Modelos de Regresión para Heterogeneidad Espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_SAR.html">Modelos de Regresión para Dependencia Espacial SAR</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_CAR.html">Modelos de Regresión para Dependencia Espacial CAR</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_Kriging.html">Kriging con Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_GP.html">Procesos Gaussianos con R</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/edieraristizabal/Libro_AnalisisGeoespacial" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/edieraristizabal/Libro_AnalisisGeoespacial/issues/new?title=Issue%20on%20page%20%2F04_GLMPoisson.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/04_GLMPoisson.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelos Lineales Generalizados (GLM) para Poisson</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-homogeneo">Poisson Homogeneo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ajuste-de-un-modelo-glm-de-poisson">Ajuste de un modelo GLM de Poisson</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-y-evaluacion-de-modelos">Comparación y evaluación de modelos</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-1-comparacion-de-valores-aic">Método 1: Comparación de valores AIC</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-2-prueba-de-chi-cuadrado-para-modelos-anidados">Método 2: Prueba de Chi-Cuadrado para Modelos Anidados.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-3-intervalos-de-confianza-para-parametros-individuales-del-modelo">Método 3: Intervalos de Confianza para Parámetros Individuales del Modelo.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-en-r">Poisson en R</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p style="font-size:11px;"><em><strong>Créditos</strong>: El contenido de este cuaderno ha sido tomado de varias fuentes, pero especialmente de <a href="https://github.com/Mark-Kramer/Case-Studies-Python/blob/master/09.ipynb">Mar Kramer</a> y <a href="https://stats.oarc.ucla.edu/r/dae/poisson-regression/">UCLA</a>. El compilador se disculpa por cualquier omisión involuntaria y estaría encantado de agregar un reconocimiento.</em></p><section class="tex2jax_ignore mathjax_ignore" id="modelos-lineales-generalizados-glm-para-poisson">
<h1>Modelos Lineales Generalizados (GLM) para Poisson<a class="headerlink" href="#modelos-lineales-generalizados-glm-para-poisson" title="Permalink to this heading">#</a></h1>
<p>Los GLM son modelos en los que las variables de respuesta siguen una distribución distinta a la distribución normal. Esto contrasta con los modelos de regresión lineal, en los que las variables de respuesta siguen una distribución normal. Esto se debe a que los Modelos Lineales Generalizados tienen variables de respuesta que son categóricas, como Sí, No; o Grupo A, Grupo B, y, por lo tanto, no varían de <span class="math notranslate nohighlight">\(-\infty\)</span> a <span class="math notranslate nohighlight">\(+\infty\)</span>. Por lo tanto, la relación entre las variables de respuesta y las variables predictoras puede no ser lineal. En GLM:</p>
<div class="math notranslate nohighlight">
\[y_i = \alpha + \beta_1x_{1i} + \beta_2x_{2i} + ... + \beta_px_{pi} + e_i \quad \text{para } i = 1, 2, ... n\]</div>
<p>La variable de respuesta <span class="math notranslate nohighlight">\(y_i\)</span> se modela mediante una función lineal de las variables predictoras y algún término de error.</p>
<p>Un modelo de Regresión de Poisson es un Modelo Lineal Generalizado (GLM) que se utiliza para modelar datos de conteo y tablas de contingencia. El resultado <span class="math notranslate nohighlight">\(Y\)</span> (conteo) es un valor que sigue la distribución de Poisson. Se asume que el logaritmo de los valores esperados (media) se puede modelar en una forma lineal mediante algunos parámetros desconocidos.</p>
<p>Para transformar la relación no lineal en una forma lineal, se utiliza una función de enlace que es el logaritmo para la Regresión de Poisson. Por esta razón, un modelo de Regresión de Poisson también se llama modelo log-lineal. La forma matemática general del modelo de Regresión de Poisson es:</p>
<p><span class="math notranslate nohighlight">\( \log(y) = \alpha + \beta\_1x_1 + \beta\_2x_2 + ... + \beta\_px_p\)</span></p>
<p>Donde,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y\)</span>: Es la variable de respuesta</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> y <span class="math notranslate nohighlight">\(\beta\)</span>: Son coeficientes numéricos, donde <span class="math notranslate nohighlight">\(\alpha\)</span> es la intersección, a veces <span class="math notranslate nohighlight">\(\alpha\)</span> también se representa por <span class="math notranslate nohighlight">\(\beta_0\)</span>, que es lo mismo</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span>: Es la variable predictora o explicativa</p></li>
</ul>
<p>Los coeficientes se calculan utilizando métodos como la Estimación de Máxima Verosimilitud (MLE) o la cuasi-verosimilitud máxima.</p>
<p>Consideremos una ecuación con una variable predictora y una variable de respuesta:</p>
<p><span class="math notranslate nohighlight">\(\log(y) = \alpha + \beta(x)\)</span></p>
<p>Esto es equivalente a:</p>
<p><span class="math notranslate nohighlight">\(y = e^{(\alpha + \beta(x))} = e^{\alpha} + e^{\beta} \cdot x\)</span></p>
<p><strong>Nota</strong>: En los modelos de Regresión de Poisson, las variables predictoras o explicativas pueden ser una mezcla de valores numéricos o categóricos.</p>
<p>Una de las características más importantes para la distribución de Poisson y la Regresión de Poisson es la equidispersión, lo que significa que la media y la varianza de la distribución son iguales.</p>
<p>La varianza mide la dispersión de los datos. Es el “promedio de las diferencias al cuadrado respecto a la media”. La varianza (Var) es igual a 0 si todos los valores son idénticos. Cuanto mayor sea la diferencia entre los valores, mayor será la varianza. La media es el promedio de los valores de un conjunto de datos. El promedio es la suma de los valores dividida por el número de valores.</p>
<p>Digamos que la media (<span class="math notranslate nohighlight">\(\mu\)</span>) está denotada por <span class="math notranslate nohighlight">\(E(X)\)</span>:</p>
<p><span class="math notranslate nohighlight">\(E(X) = \mu\)</span></p>
<p>Para la Regresión de Poisson, la media y la varianza están relacionadas de la siguiente manera:</p>
<p><span class="math notranslate nohighlight">\(\text{var}(X) = \sigma^2E(X)\)</span></p>
<p>Donde <span class="math notranslate nohighlight">\(\sigma^2\)</span> es el parámetro de dispersión. Dado que <span class="math notranslate nohighlight">\(\text{var}(X) = E(X)\)</span> (varianza = media) debe cumplirse para que el modelo de Poisson se ajuste completamente, <span class="math notranslate nohighlight">\(\sigma^2\)</span> debe ser igual a 1.</p>
<p>Cuando la varianza es mayor que la media, eso se llama sobredispersión y es mayor que 1. Si es menor que 1, se conoce como subdispersión.</p>
<p>El proceso de puntos de Poisson, o proceso de Poisson, o campo de puntos de Poisson, es un tipo de objeto aleatorio que consiste en puntos posicionados aleatoriamente ubicados en algún espacio matemático subyacente. El proceso de puntos de Poisson está relacionado con la distribución de Poisson, que implica que la probabilidad de que una variable aleatoria de Poisson <span class="math notranslate nohighlight">\(N\)</span> sea igual a <span class="math notranslate nohighlight">\(n\)</span> es:</p>
<p><span class="math notranslate nohighlight">\( 
P\{N = n\} = \frac{\lambda^n e^{-\lambda}}{n!} 
\)</span></p>
<p>donde <span class="math notranslate nohighlight">\(n!\)</span> denota el factorial de <span class="math notranslate nohighlight">\(n\)</span> y <span class="math notranslate nohighlight">\(\lambda\)</span> es el parámetro único de Poisson que se usa para definir la distribución de Poisson.</p>
<p>El proceso de puntos de Poisson a veces se llama proceso puramente o completamente aleatorio. Este proceso tiene la propiedad de que el número de eventos <span class="math notranslate nohighlight">\(N(A)\)</span> en una región acotada <span class="math notranslate nohighlight">\(A \in \mathbb{R}^d\)</span> está distribuido de manera independiente y uniforme sobre <span class="math notranslate nohighlight">\(A\)</span>. Esto significa que la ubicación de un punto no afecta las probabilidades de que otros puntos aparezcan cerca y que no hay regiones donde los eventos sean más propensos a aparecer.</p>
<p>Si un proceso de puntos de Poisson tiene un parámetro constante, digamos, <span class="math notranslate nohighlight">\(\lambda\)</span>, entonces se llama proceso de <strong>Poisson homogéneo (o estacionario) (HPP)</strong>. El parámetro <span class="math notranslate nohighlight">\(\lambda\)</span>, llamado intensidad, está relacionado con el número esperado (o promedio) de puntos de Poisson que existen en alguna región acotada. El parámetro <span class="math notranslate nohighlight">\(\lambda\)</span> se puede interpretar como el número promedio de puntos por alguna unidad de longitud, área o volumen, dependiendo del espacio matemático subyacente, por lo que a veces se llama densidad media.</p>
<p>El HPP es estacionario y los patrones y procesos de puntos espaciales son isotrópicos. Es estacionario porque la intensidad es constante y, además, es isotrópico porque la intensidad es invariante a la rotación de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>.</p>
<p>Una generalización del HPP que permite una intensidad no constante <span class="math notranslate nohighlight">\(\lambda\)</span> se llama proceso de <strong>Poisson no-homogéneo (IPP)</strong>. Tanto el HPP como el IPP asumen que los eventos ocurren de manera independiente y están distribuidos según una intensidad dada, <span class="math notranslate nohighlight">\(\lambda\)</span>. La principal diferencia es que el HPP asume que la función de intensidad es constante (<span class="math notranslate nohighlight">\(\lambda = \text{const.}\)</span>), mientras que la intensidad de un IPP varía espacialmente (<span class="math notranslate nohighlight">\(\lambda = Z(u)\)</span>).</p>
<p>En el plano <span class="math notranslate nohighlight">\((\mathbb{R}^2)\)</span>, el proceso de puntos de Poisson se conoce como <strong>proceso de Poisson espacial</strong>. En una región acotada <span class="math notranslate nohighlight">\(A\)</span> en un plano <span class="math notranslate nohighlight">\((\mathbb{R}^2)\)</span>, con <span class="math notranslate nohighlight">\(N(A)\)</span> siendo el número (aleatorio) de puntos <span class="math notranslate nohighlight">\(N\)</span> que existen en la región <span class="math notranslate nohighlight">\(A \subset \mathbb{R}^2\)</span>, un proceso de Poisson homogéneo con parámetro <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> describe la probabilidad de que existan <span class="math notranslate nohighlight">\(n\)</span> puntos en <span class="math notranslate nohighlight">\(A\)</span> mediante:</p>
<p><span class="math notranslate nohighlight">\( 
P\{N(A) = n\} = \frac{\lambda^{|A|} (|A|)^n}{n!} e^{-\lambda |A|} 
\)</span></p>
<p>donde <span class="math notranslate nohighlight">\(|A|\)</span> denota el área de <span class="math notranslate nohighlight">\(A\)</span>.</p>
<section id="poisson-homogeneo">
<h2>Poisson Homogeneo<a class="headerlink" href="#poisson-homogeneo" title="Permalink to this heading">#</a></h2>
<section id="ajuste-de-un-modelo-glm-de-poisson">
<h3>Ajuste de un modelo GLM de Poisson<a class="headerlink" href="#ajuste-de-un-modelo-glm-de-poisson" title="Permalink to this heading">#</a></h3>
<p>Cualquier modelo estadístico que describa datos que ocurren en puntos localizados en el tiempo, como los tiempos de disparo de neuronas, se denomina modelo de proceso puntual temporal. Aquí, queremos construir un modelo estadístico que describa la distribución de probabilidad de los tiempos de espera entre los disparos para una neurona sin un estímulo de conducción explícito, en este caso, el modelo debería caracterizar cómo la distribución de los datos depende de las covariables de interés: la posición del ratón y la dirección del movimiento.</p>
<p>Un enfoque utilizado para modelar datos enteros positivos es un modelo de Poisson, en el que usamos un parámetro de tasa, <span class="math notranslate nohighlight">\(\lambda\)</span>, para definir la tasa esperada de disparos en cualquier intervalo de tiempo. Para los datos de interés aquí, ampliamos este concepto definiendo una tasa que varía en el tiempo como una función de un conjunto de covariables. Estas covariables son cualquier variable cuya influencia sobre la actividad de disparo deseemos explorar. Nuestras visualizaciones sugieren que las covariables útiles para nuestro modelo incluyen la posición del ratón y su dirección de movimiento.</p>
<p>Definamos algunos términos. Dejemos que <span class="math notranslate nohighlight">\(X(t)\)</span> represente la posición del ratón en el tiempo <span class="math notranslate nohighlight">\(t\)</span>, y que <span class="math notranslate nohighlight">\(D(t)\)</span> represente la dirección del movimiento; establecemos <span class="math notranslate nohighlight">\(D(t) = -1\)</span> cuando <span class="math notranslate nohighlight">\(X(t)\)</span> está disminuyendo o el ratón está detenido, y <span class="math notranslate nohighlight">\(D(t) = +1\)</span> cuando <span class="math notranslate nohighlight">\(X(t)\)</span> está aumentando. Dado que estas señales de posición y dirección cambian en función del tiempo, también lo hace la tasa de disparo. Escribimos <span class="math notranslate nohighlight">\(\lambda(t) = f(X(t), D(t))\)</span>, donde <span class="math notranslate nohighlight">\(\lambda(t)\)</span> se llama la función de tasa de Poisson, y <span class="math notranslate nohighlight">\(f\)</span> es una función que necesitamos para definir el modelo.</p>
<p>¿Qué función deberíamos usar para <span class="math notranslate nohighlight">\(f(X(t), D(t))\)</span>? Queremos algo que capture la relación entre las covariables y los disparos, y que sea fácil de interpretar. El proceso de encontrar un modelo o conjunto de modelos que sean más consistentes con los datos se llama identificación de modelos o selección de modelos. Típicamente, este es un proceso iterativo en el que proponemos una clase de modelos, encontramos el modelo particular en esa clase que mejor se ajusta a los datos, evaluamos la calidad de ese modelo y decidimos si refinar el modelo aún más o sacar conclusiones del ajuste del modelo. En la práctica, es una buena idea comenzar con estadísticas descriptivas y visualizaciones de la relación entre las covariables y los datos de disparo para seleccionar una clase de modelos de proceso puntual. Para los datos de tren de disparo de interés aquí, nuestras visualizaciones sugieren un modelo donde la dependencia del disparo en la posición tiene una forma de montículo (como en el histograma normalizado por ocupación) e incorpora la dirección. Comenzamos con un modelo demasiado simple para fines pedagógicos.</p>
<p>El siguiente es un modelo muy básico inspirado en la regresión lineal simple:</p>
<p><span class="math notranslate nohighlight">\(
\lambda(t) = \beta_0 + \beta_1 X(t)
\)</span></p>
<p>La idea de la regresión lineal es expresar una variable de respuesta en el tiempo <span class="math notranslate nohighlight">\(t\)</span> en términos de variables predictoras, o covariables. Aquí, <span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span> son parámetros desconocidos utilizados para caracterizar una dependencia lineal entre la variable de respuesta <span class="math notranslate nohighlight">\(\lambda(t)\)</span> y la covariable <span class="math notranslate nohighlight">\(X(t)\)</span>. <span class="math notranslate nohighlight">\(\beta_0\)</span> representa la tasa de disparo esperada en <span class="math notranslate nohighlight">\(X(t) = 0\)</span>, y <span class="math notranslate nohighlight">\(\beta_1\)</span> representa el cambio en la tasa de disparo por cada unidad de aumento en la posición. Este modelo inicial no incluye ninguna dependencia en la dirección de movimiento del ratón (es decir, no hay término <span class="math notranslate nohighlight">\(D(t)\)</span>).</p>
<p>La forma del modelo se parece a una regresión lineal estándar, lo cual es reconfortante porque existen métodos en Python para resolver este tipo de problemas. Sin embargo, los datos observados son eventos de disparo; en tiempo discreto, los datos son conteos de disparos. Una regresión lineal estándar asume que la distribución de los datos, dadas las covariables, es normal. Los conteos de disparos solo pueden tomar valores enteros no negativos, por lo que su distribución no puede ser normal. Cuando el número de conteos de disparos en cada intervalo de tiempo es muy grande, es posible que la distribución de los datos pueda aproximarse por una distribución normal, y en este caso, los métodos de regresión simple podrían funcionar. Pero para los datos de disparo de interés aquí, tenemos muy pocos disparos (0 o 1) en cada intervalo de tiempo de 1 ms, por lo que un ajuste de regresión simple no sería correcto.</p>
<p>En su lugar, debemos ajustar un modelo de regresión de Poisson a los datos. Si dejamos que <span class="math notranslate nohighlight">\(Y_i\)</span> sea el número de disparos observados en el intervalo <span class="math notranslate nohighlight">\(i\)</span>, entonces bajo el modelo de regresión de Poisson, <span class="math notranslate nohighlight">\(Y_i\)</span> tiene una distribución de Poisson con un parámetro de media igual a la variable de respuesta <span class="math notranslate nohighlight">\(\lambda(t)\)</span> integrada sobre el intervalo <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>¿Cómo ajustamos el modelo de regresión de Poisson? Resulta que los modelos de regresión de Poisson de cierta forma se pueden ajustar de manera eficiente utilizando la teoría de modelos lineales generalizados (GLM). En Python, podemos ajustar este modelo utilizando el paquete <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. Antes de aplicar esta función directamente a los datos, obtengamos una visión general de las entradas y salidas de la función. En Python, consideramos el modelo GLM del paquete <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. Construiremos un modelo usando:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">GLM</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X_1</span><span class="p">,</span> <span class="n">family</span><span class="p">(</span><span class="n">link</span><span class="p">()))</span>
</pre></div>
</div>
<p>La primera entrada, <span class="math notranslate nohighlight">\(Y\)</span>, es un vector de los conteos de disparos en cada paso de tiempo. En este caso, <span class="math notranslate nohighlight">\(Y\)</span> es el vector <code class="docutils literal notranslate"><span class="pre">spiketrain</span></code> que calculamos anteriormente. La segunda entrada, <span class="math notranslate nohighlight">\(X_1\)</span>, es una matriz de las covariables de las que depende el disparo. El tamaño de esta matriz es <span class="math notranslate nohighlight">\(n \times p\)</span>, donde <span class="math notranslate nohighlight">\(p\)</span> es el número de covariables en el modelo, y <span class="math notranslate nohighlight">\(n\)</span> es el número de observaciones. Dado que nuestro modelo está dado por <span class="math notranslate nohighlight">\(\lambda(t) = \beta_0 + \beta_1 X(t)\)</span>, añadiremos una columna de unos a la matriz de datos <span class="math notranslate nohighlight">\(X\)</span>, para que podamos ajustar la intersección <span class="math notranslate nohighlight">\(\beta_0\)</span> a nuestros datos. Por lo tanto, <span class="math notranslate nohighlight">\(X_1\)</span> es una matriz <span class="math notranslate nohighlight">\(n \times 2\)</span>, donde <span class="math notranslate nohighlight">\(n\)</span> es el número de puntos de datos (177,761) que representan la posición del ratón a lo largo de la pista. La tercera entrada indica la distribución de los datos de conteo de disparos en <span class="math notranslate nohighlight">\(Y\)</span>. Para un modelo de regresión de Poisson de datos de conteo de disparos, utilizamos la familia de Poisson. De hecho, para la mayoría de los modelos de conteo de disparos neuronales ajustados utilizando GLM, incluso aquellos que no son procesos de Poisson, utilizamos la distribución de Poisson. La entrada <code class="docutils literal notranslate"><span class="pre">family</span></code> se caracteriza por una función de enlace entre la tasa de disparo y las covariables. Específicamente, si queremos ajustar un modelo de la forma <span class="math notranslate nohighlight">\(\lambda(t) = \exp(\beta_0 + \beta_1 X(t))\)</span>, entonces diríamos que la función <span class="math notranslate nohighlight">\(\log(\lambda(t)) = \beta_0 + \beta_1 X(t)\)</span> es la función de enlace. Para el Modelo 1, esta es simplemente la función identidad. A continuación, mostramos una mejor manera de seleccionar esta función de enlace.</p>
<p>El atributo <code class="docutils literal notranslate"><span class="pre">params</span></code> de la función <code class="docutils literal notranslate"><span class="pre">fit</span></code> es un vector de números que representa las estimaciones de máxima verosimilitud de los parámetros del modelo, que para este ejemplo hemos etiquetado como <span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span>. Usamos la notación con “sombrero” (hat) sobre un parámetro para representar su estimación. La estimación de máxima verosimilitud de <span class="math notranslate nohighlight">\(\beta_0\)</span> se escribe como <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>, y la estimación de máxima verosimilitud de <span class="math notranslate nohighlight">\(\beta_1\)</span> se escribe como <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span>. Ahora, usemos esta función para ajustar los parámetros del Modelo 1 a los datos observados de ubicación y disparos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/Mark-Kramer/Case-Studies-Python/raw/master/matfiles/spikes-1.mat&#39;</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">open</span><span class="p">(</span><span class="s1">&#39;spikles-1.mat&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1761663
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">loadmat</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loadmat</span><span class="p">(</span><span class="s2">&quot;spikles-1.mat&quot;</span><span class="p">)</span>  
<span class="n">t</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;t&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span>             
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>                     
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3843ed459d6f20ac0f1426e73854ded5149ef31b2a4ad6f1dd8f049cea642a52.png" src="_images/3843ed459d6f20ac0f1426e73854ded5149ef31b2a4ad6f1dd8f049cea642a52.png" />
</div>
</div>
<p>El gráfico muestra que la rata corre de un lado a otro de manera consistente, realizando aproximadamente 15 pasadas durante los 3 minutos de grabación. También observamos que la rata se mueve bastante rápido en cada pasada, pero pasa una gran cantidad de tiempo en ambos extremos de la pista (cerca de la posición 0 cm o 100 cm) antes de girar y continuar.</p>
<p>A continuación, nos gustaría graficar la actividad de disparo en relación con la trayectoria de movimiento de la rata. Sin embargo, no podemos simplemente graficar el vector X contra el vector spiketimes; estos vectores tienen longitudes diferentes. La longitud de X es la misma que la longitud de t, el número total de intervalos de tiempo de 1 ms en la grabación (177,761 intervalos de tiempo). La longitud de spiketimes es el número total de picos que ocurrieron durante la duración de la grabación: 220 picos. Por lo tanto, el primer paso para visualizar la actividad de disparo específica del lugar es usar spiketimes para crear un nuevo vector, del mismo tamaño que X, que indique si se produjo un pico en cada intervalo de tiempo. Llamaremos a este vector spiketrain, y contendrá un 1 para cada intervalo de tiempo donde ocurre un pico y un 0 para cada intervalo de tiempo que no tiene un pico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spiketimes</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;spiketimes&#39;</span><span class="p">]</span>
<span class="n">n_bins</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="c1"># Histogram spikes into bins centered at times t:</span>
<span class="n">spiketrain</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">spiketimes</span><span class="p">,</span> 
                         <span class="n">bins</span> <span class="o">=</span> <span class="n">n_bins</span><span class="p">,</span> 
                         <span class="nb">range</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">line</span> <span class="mi">4</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">n_bins</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># Histogram spikes into bins centered at times t:</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="n">spiketrain</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">spiketimes</span><span class="p">,</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span>                          <span class="n">bins</span> <span class="o">=</span> <span class="n">n_bins</span><span class="p">,</span> 
<span class="g g-Whitespace">      </span><span class="mi">6</span>                          <span class="nb">range</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\pyplot.py:2645,</span> in <span class="ni">hist</span><span class="nt">(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2639</span> <span class="nd">@_copy_docstring_and_deprecators</span><span class="p">(</span><span class="n">Axes</span><span class="o">.</span><span class="n">hist</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2640</span> <span class="k">def</span> <span class="nf">hist</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">2641</span>         <span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2642</span>         <span class="n">cumulative</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;mid&#39;</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2643</span>         <span class="n">orientation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2644</span>         <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">2645</span>     <span class="k">return</span> <span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">2646</span>         <span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="nb">range</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="n">density</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2647</span>         <span class="n">cumulative</span><span class="o">=</span><span class="n">cumulative</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="n">bottom</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="n">histtype</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2648</span>         <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="n">orientation</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="n">rwidth</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2649</span>         <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="n">stacked</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">2650</span>         <span class="o">**</span><span class="p">({</span><span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">}</span> <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\__init__.py:1461,</span> in <span class="ni">_preprocess_data.&lt;locals&gt;.inner</span><span class="nt">(ax, data, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1458</span> <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1459</span> <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1460</span>     <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1461</span>         <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">sanitize_sequence</span><span class="p">,</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1463</span>     <span class="n">bound</span> <span class="o">=</span> <span class="n">new_sig</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1464</span>     <span class="n">auto_label</span> <span class="o">=</span> <span class="p">(</span><span class="n">bound</span><span class="o">.</span><span class="n">arguments</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label_namer</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1465</span>                   <span class="ow">or</span> <span class="n">bound</span><span class="o">.</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label_namer</span><span class="p">))</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\axes\_axes.py:6851,</span> in <span class="ni">Axes.hist</span><span class="nt">(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">6849</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">6850</span>     <span class="n">height</span> <span class="o">=</span> <span class="n">top</span>
<span class="ne">-&gt; </span><span class="mi">6851</span> <span class="n">bars</span> <span class="o">=</span> <span class="n">_barfunc</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">boffset</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">6852</span>                 <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">6853</span>                 <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="n">bottom_kwarg</span><span class="p">:</span> <span class="n">bottom</span><span class="p">})</span>
<span class="g g-Whitespace">   </span><span class="mi">6854</span> <span class="n">patches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bars</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">6855</span> <span class="k">if</span> <span class="n">stacked</span><span class="p">:</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\__init__.py:1461,</span> in <span class="ni">_preprocess_data.&lt;locals&gt;.inner</span><span class="nt">(ax, data, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1458</span> <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1459</span> <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1460</span>     <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1461</span>         <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">sanitize_sequence</span><span class="p">,</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1463</span>     <span class="n">bound</span> <span class="o">=</span> <span class="n">new_sig</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1464</span>     <span class="n">auto_label</span> <span class="o">=</span> <span class="p">(</span><span class="n">bound</span><span class="o">.</span><span class="n">arguments</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label_namer</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1465</span>                   <span class="ow">or</span> <span class="n">bound</span><span class="o">.</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label_namer</span><span class="p">))</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\axes\_axes.py:2486,</span> in <span class="ni">Axes.bar</span><span class="nt">(self, x, height, width, bottom, align, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">2484</span>     <span class="k">else</span><span class="p">:</span>  <span class="c1"># horizontal</span>
<span class="g g-Whitespace">   </span><span class="mi">2485</span>         <span class="n">r</span><span class="o">.</span><span class="n">sticky_edges</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">2486</span>     <span class="bp">self</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2487</span>     <span class="n">patches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2489</span> <span class="k">if</span> <span class="n">xerr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">yerr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\axes\_base.py:2379,</span> in <span class="ni">_AxesBase.add_patch</span><span class="nt">(self, p)</span>
<span class="g g-Whitespace">   </span><span class="mi">2377</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">get_clip_path</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">2378</span>     <span class="n">p</span><span class="o">.</span><span class="n">set_clip_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">patch</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">2379</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_patch_limits</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2380</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2381</span> <span class="n">p</span><span class="o">.</span><span class="n">_remove_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">remove</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\axes\_base.py:2401,</span> in <span class="ni">_AxesBase._update_patch_limits</span><span class="nt">(self, patch)</span>
<span class="g g-Whitespace">   </span><span class="mi">2398</span> <span class="c1"># Get all vertices on the path</span>
<span class="g g-Whitespace">   </span><span class="mi">2399</span> <span class="c1"># Loop through each segment to get extrema for Bezier curve sections</span>
<span class="g g-Whitespace">   </span><span class="mi">2400</span> <span class="n">vertices</span> <span class="o">=</span> <span class="p">[]</span>
<span class="ne">-&gt; </span><span class="mi">2401</span> <span class="k">for</span> <span class="n">curve</span><span class="p">,</span> <span class="n">code</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">iter_bezier</span><span class="p">(</span><span class="n">simplify</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">2402</span>     <span class="c1"># Get distance along the curve of any extrema</span>
<span class="g g-Whitespace">   </span><span class="mi">2403</span>     <span class="n">_</span><span class="p">,</span> <span class="n">dzeros</span> <span class="o">=</span> <span class="n">curve</span><span class="o">.</span><span class="n">axis_aligned_extrema</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">2404</span>     <span class="c1"># Calculate vertices of start, end and any extrema in between</span>

<span class="nn">File ~\miniconda3\Lib\site-packages\matplotlib\path.py:459,</span> in <span class="ni">Path.iter_bezier</span><span class="nt">(self, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">456</span>     <span class="k">yield</span> <span class="n">BezierSegment</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">prev_vert</span><span class="p">,</span> <span class="n">verts</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
<span class="g g-Whitespace">    </span><span class="mi">457</span>                                   <span class="n">verts</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="n">verts</span><span class="p">[</span><span class="mi">4</span><span class="p">:]])),</span> <span class="n">code</span>
<span class="g g-Whitespace">    </span><span class="mi">458</span> <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="n">Path</span><span class="o">.</span><span class="n">CLOSEPOLY</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">459</span>     <span class="k">yield</span> <span class="n">BezierSegment</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">prev_vert</span><span class="p">,</span> <span class="n">first_vert</span><span class="p">])),</span> <span class="n">code</span>
<span class="g g-Whitespace">    </span><span class="mi">460</span> <span class="k">elif</span> <span class="n">code</span> <span class="o">==</span> <span class="n">Path</span><span class="o">.</span><span class="n">STOP</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">461</span>     <span class="k">return</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">spikeindex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">spiketrain</span><span class="o">!=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>     <span class="c1"># Get the spike indices.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>                               <span class="c1"># Plot the position,</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">spikeindex</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">spikeindex</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>  <span class="c1"># ... and the spikes.  </span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [sec]&#39;</span><span class="p">)</span>                     <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e7aa3addaf360706673e1252db755523a2797bf8e4400559214d27cf59eb77d9.png" src="_images/e7aa3addaf360706673e1252db755523a2797bf8e4400559214d27cf59eb77d9.png" />
</div>
</div>
<p>A partir de la figura anterior, está claro que la mayor parte de la actividad de picos ocurre cuando la rata está corriendo hacia arriba en la pista, en la dirección donde X está aumentando, en valores de X que van desde unos 50 cm hasta unos 80 cm. No vemos la misma actividad de picos en esta región cuando la rata está corriendo hacia abajo en la pista, en la dirección donde X está disminuyendo. Algunos picos ocurren en otras ubicaciones, pero estos parecen escasos en comparación con el disparo específico de lugar en esta región.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">106</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>                              <span class="c1"># Define spatial bins.</span>
<span class="n">spikehist</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">spikeindex</span><span class="p">],</span> <span class="n">bin_edges</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>           <span class="c1"># Histogram positions @ spikes.</span>
<span class="n">occupancy</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mf">0.001</span>                 <span class="c1"># Convert occupancy to seconds.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">spikehist</span><span class="o">/</span><span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                                      <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c87a0ed17ad49bd0cdc5345028658f4a15ef2db615c9c3c5669840da33729fb4.png" src="_images/c87a0ed17ad49bd0cdc5345028658f4a15ef2db615c9c3c5669840da33729fb4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.genmod.families</span> <span class="kn">import</span> <span class="n">Poisson</span>
<span class="kn">from</span> <span class="nn">statsmodels.genmod.families.links</span> <span class="kn">import</span> <span class="n">identity</span>

<span class="c1"># Create a dataframe of predictors that includes X and a constant term</span>
<span class="n">predictors</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Intercept&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>

<span class="c1"># GLM model with Poisson family and identity link function</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">(</span><span class="n">identity</span><span class="p">()))</span>
<span class="n">model1_results</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># Fit model to our data</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">model1_results</span><span class="o">.</span><span class="n">params</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b1:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\edier\miniconda3\envs\carto\Lib\site-packages\statsmodels\genmod\families\links.py:13: FutureWarning: The identity link alias is deprecated. Use Identity instead. The identity link alias will be removed after the 0.15.0 release.
  warnings.warn(
C:\Users\edier\miniconda3\envs\carto\Lib\site-packages\statsmodels\genmod\generalized_linear_model.py:307: DomainWarning: The identity link function does not respect the domain of the Poisson family.
  warnings.warn((f&quot;The {type(family.link).__name__} link function &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b1:
Intercept   -0.000097
X            0.000027
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Inicialmente, es posible que notes que Python emite una advertencia en la línea de comandos indicando que este modelo—particularmente la función de enlace de identidad—puede ser inapropiado. Ignoraremos esta advertencia e intentaremos interpretar las estimaciones de los parámetros resultantes. El primero de estos valores es la estimación de máxima verosimilitud para <span class="math notranslate nohighlight">\(\beta_0\)</span>. Si creemos que este modelo es preciso, podríamos interpretar este parámetro como indicativo de que la tasa de disparo esperada en la posición <span class="math notranslate nohighlight">\(X(t) = 0\)</span> es de <span class="math notranslate nohighlight">\(-0.097\)</span> picos por milisegundo, o aproximadamente <span class="math notranslate nohighlight">\(-0.097\)</span> picos por segundo, y que a medida que la rata se mueve en la dirección positiva, la tasa de disparo aumenta en <span class="math notranslate nohighlight">\(\beta_1\)</span> picos por segundo por cada centímetro que la rata se mueve.</p>
<p>Este resultado debería levantar algunas señales de advertencia de inmediato. El hecho de que la tasa de disparo sea negativa indica que el modelo se vuelve ininterpretable para los valores observados de <span class="math notranslate nohighlight">\(X(t)\)</span>. Esto sugiere un problema importante con el Modelo 1: la tasa de disparo es negativa, lo que motiva cambios en la función de enlace del modelo. Para visualizar mejor la calidad de este modelo, podemos comparar la dependencia que define entre la posición y la tasa de disparo con el histograma normalizado por ocupación que calculamos anteriormente. En este caso, utilizamos las posiciones definidas por los intervalos del histograma y calculamos la tasa de disparo modelada en estos puntos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">spikehist</span><span class="o">/</span><span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>    <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,(</span><span class="n">b1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">b1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">bins</span><span class="p">)</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>
     <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Model spike rate&quot;</span><span class="p">)</span>             <span class="c1"># Plot model.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                    <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;b1 = [</span><span class="si">{0[0]:.4}</span><span class="s2">, </span><span class="si">{0[1]:.4}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">b1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/27981b044f38b90d2b5989db673836a56584947c3eb10d0c28c8d9c5d2a3a2b2.png" src="_images/27981b044f38b90d2b5989db673836a56584947c3eb10d0c28c8d9c5d2a3a2b2.png" />
</div>
</div>
<p>Vemos que la tasa de disparo del modelo captura algunas características del disparo observado, por ejemplo, el hecho de que la tasa de disparo aumenta a medida que la rata se mueve desde la posición <span class="math notranslate nohighlight">\(x = 0\)</span> hacia la posición <span class="math notranslate nohighlight">\(x = 60\)</span>. Pero el modelo no capta gran parte de la estructura, por ejemplo, el hecho de que la tasa de disparo no cambia linealmente con la posición y comienza a disminuir cuando la posición de la rata supera los <span class="math notranslate nohighlight">\(x = 70\)</span>. Esto sugiere un segundo problema con este modelo: la forma de la relación entre la posición y la tasa de disparo es incorrecta.</p>
<p>Concluimos que nuestra propuesta inicial, el Modelo 1, no representa bien los datos. Por lo tanto, refinemos el modelo para abordar los problemas identificados. Primero, elijamos una función de enlace que sea más apropiada para el modelado de procesos puntuales. Nos gustaría una función que asegure que la función de tasa sea no negativa y que sea fácil de ajustar. La teoría del modelado lineal generalizado sugiere una función en particular: el enlace logarítmico. Establecemos que el logaritmo de la tasa de disparo sea una función lineal de las covariables. Si mantenemos la posición como la única covariable, esto conduce a un modelo de la forma:</p>
<div class="math notranslate nohighlight">
\[
\log(\lambda(t)) = \beta_0 + \beta_1 X(t)
\]</div>
<p>o, de manera equivalente,</p>
<div class="math notranslate nohighlight">
\[
\lambda(t) = \exp(\beta_0 + \beta_1 X(t))
\]</div>
<p>Esta función de enlace se llama el enlace canónico para datos de Poisson. Tiene una serie de propiedades atractivas. Como se deseaba, asegura que la función de tasa sea positiva.</p>
<p><strong>P:</strong> Considera la expresión para <span class="math notranslate nohighlight">\(\lambda(t)\)</span> arriba. ¿Por qué <span class="math notranslate nohighlight">\(\lambda(t)\)</span> debe ser siempre positiva?</p>
<p>La elección de un enlace logarítmico también asegura que la verosimilitud de los datos sea cóncava con respecto a los parámetros del modelo. Esto significa que la verosimilitud solo tiene un valor máximo local, que es la estimación de máxima verosimilitud (ML). También se puede demostrar que, en muchos casos, los estimadores de los parámetros serán asintóticamente normales, lo que nos permitirá construir intervalos de confianza y hacer declaraciones de significancia sobre ellos [Kass, Eden &amp; Brown, 2014].</p>
<p>Para ajustar el Modelo 2 en Python, usamos el mismo modelo que antes pero reemplazamos la función de enlace con <span class="math notranslate nohighlight">\(\log\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span> <span class="c1"># GLM model with Poisson family and log link function</span>
<span class="n">model2_results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># Fit model to our data</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">params</span>    <span class="c1"># Get the predicted coefficient vector</span>
</pre></div>
</div>
</div>
</div>
<p>De hecho, si omitimos el nombre de la función de enlace en la rutina <code class="docutils literal notranslate"><span class="pre">sm.GLM</span></code>, esta usará automáticamente el enlace canónico para la distribución seleccionada. Dado que el enlace logarítmico es canónico para datos de Poisson, simplemente podemos ejecutar los comandos:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span>  <span class="c1"># GLM model with Poisson family, omitting link function</span>
<span class="n">model2_results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>  <span class="c1"># Fit model to our data</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">params</span>     <span class="c1"># Get the predicted coefficient vector</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -7.438887
X            0.012943
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Esta vez, encontramos que Python no emite una advertencia sobre la posible inapropiedad de la función de enlace. La inspección de los valores estimados de los parámetros revela <span class="math notranslate nohighlight">\(b_2 = [-7.43888719, 0.01294342]\)</span>. Estos valores son marcadamente diferentes de los valores de parámetros <span class="math notranslate nohighlight">\(b_1\)</span> encontrados usando el Modelo 1. La razón de esta diferencia es que la forma del modelo tiene un impacto importante en la interpretación de los valores de los parámetros. A continuación, discutimos la interpretación de estos valores de los parámetros en detalle.</p>
<p>Examinemos el ajuste del modelo más de cerca. Cuando <span class="math notranslate nohighlight">\(x = 0\)</span>, la tasa de disparo bajo el Modelo 2 es</p>
<p>\begin{align}
\lambda(t) &amp;= \exp(\beta_0 + \beta_1 \times 0) \
&amp;= \exp(\beta_0) \
&amp;= 0.0006\text{ spikes/ms} \
&amp;= 0.6 \text{ spikes/s}
\end{align}</p>
<p>donde hemos utilizado el valor <span class="math notranslate nohighlight">\(b_2[0]\)</span>. Si el ratón se mueve de la posición <span class="math notranslate nohighlight">\(x = 0\)</span> a <span class="math notranslate nohighlight">\(x = 1\)</span>, la tasa de disparo se convierte en</p>
<p>\begin{align}\lambda(t) &amp;= \exp(\beta_0 + \beta_1 × 1) \
&amp;= \exp(\beta_0 + \beta_1)\
&amp;= \exp(\beta_0)\exp(\beta_1)\
&amp;= 1.013 \exp(\beta_0),\end{align}</p>
<p>donde hemos utilizado el valor <span class="math notranslate nohighlight">\(b_2[1]\)</span>. Es decir, un aumento de 1 cm en la posición incrementa la tasa de disparo en un 1.3%. Debido a la función de enlace, la posición ahora tiene un efecto multiplicativo en lugar de aditivo sobre la tasa de disparo. En lugar de sumar a la tasa de disparo, cada aumento de posición conduce a una modulación multiplicativa de la tasa de disparo, con un incremento de aproximadamente un 1% por cm. Veamos cómo se ve este modelo comparándolo con el histograma normalizado por ocupación de los datos. En Python,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">spikehist</span><span class="o">/</span><span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>    <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">b2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">bins</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>
     <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model spike rate&#39;</span><span class="p">)</span>             <span class="c1"># Plot model.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                    <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/93d02baa10681e62f5b1a84c5eba3d884b6a4de1230b4a41757489195e2a822c.png" src="_images/93d02baa10681e62f5b1a84c5eba3d884b6a4de1230b4a41757489195e2a822c.png" />
</div>
</div>
<p>La inspección visual sugiere que hemos resuelto un problema: la tasa de disparo ya no es negativa en ningún lugar. Sin embargo, el ajuste del modelo aún no concuerda con la estructura observada en el histograma normalizado por ocupación. Hemos mejorado la función de enlace, pero usar solo la posición como covariable lleva a una tasa que es una función exponencial de la posición del ratón.</p>
<p>Hay muchas variables que podríamos considerar agregar a este modelo, pero ¿qué variables podríamos añadir para capturar mejor la dependencia entre la tasa de disparo y la posición, en particular? Una idea podría ser incluir términos no lineales, como el cuadrado del valor de la posición. Esto nos da un tercer modelo candidato:</p>
<div class="math notranslate nohighlight">
\[
\lambda(t) = \exp(\beta_0 + \beta_1 \times \text{posición} + \beta_2 \times \text{posición}^2)
\]</div>
<p>Comparado con el Modelo 2, ahora hemos incluido un término adicional <span class="math notranslate nohighlight">\(\text{posición}^2\)</span> y un coeficiente desconocido <span class="math notranslate nohighlight">\(\beta_2\)</span>.</p>
<p><strong>P:</strong> Dijimos anteriormente que usaríamos modelos lineales generalizados. ¿Viola el uso del término no lineal <span class="math notranslate nohighlight">\(\text{posición}^2\)</span> esto?</p>
<p><strong>R:</strong> Puede ser mejor pensar en “lineal” en “modelos lineales generalizados” como que requiere que alguna función de la media de la variable de respuesta sea una función lineal de los coeficientes (es decir, los <span class="math notranslate nohighlight">\(\beta\)</span>). Las covariables pueden ser funciones lineales o no lineales de las cantidades observadas (por ejemplo, el cuadrado de la posición, el seno del ángulo de dirección de la cabeza, etc.)</p>
<p>Para ajustar el Modelo 3 en Python, agregamos otra columna a la matriz de covariables, el segundo argumento del modelo GLM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit Model 3 to the spike train data (omitting last input).</span>
<span class="n">predictors</span><span class="p">[</span><span class="s1">&#39;X2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span>       <span class="c1"># Add column for X^2</span>

<span class="c1"># GLM model with Poisson family and identity link function</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span>
<span class="n">model3_results</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># Fit model to our data</span>
<span class="n">b3</span> <span class="o">=</span> <span class="n">model3_results</span><span class="o">.</span><span class="n">params</span>    <span class="c1"># Get the predicted coefficient vector</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b3:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b3:
 Intercept   -26.279057
X             0.690114
X2           -0.005463
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Al igual que con el Modelo 2, encontramos que Python no produce advertencias de que la función de enlace pueda ser inapropiada. En este caso, hay tres valores de parámetros estimados en <span class="math notranslate nohighlight">\(\mathbf{b}_3\)</span>.</p>
<p>Ahora, interpretemos las estimaciones de los parámetros para el Modelo 3. La estimación del primer parámetro es <span class="math notranslate nohighlight">\(\beta_0=-26.3\)</span>. Esto significa que cuando el ratón está en la posición <span class="math notranslate nohighlight">\(x = 0\)</span>, la tasa de disparo es <span class="math notranslate nohighlight">\(\lamda = \exp(\beta_0)=-26.3=0\)</span>. Hay casi ninguna posibilidad de observar un disparo cuando el ratón está en esta ubicación. ¿Qué sucede cuando el ratón se mueve en la dirección positiva? Esto está determinado tanto por <span class="math notranslate nohighlight">\(\beta_1=0.6901\)</span> como por <span class="math notranslate nohighlight">\(\beta_2=-0.0055\)</span>. Por cada incremento unitario en la posición, la tasa de disparo se multiplica por <span class="math notranslate nohighlight">\(\exp(\beta_1)=1.99\)</span>, pero al mismo tiempo, por cada incremento unitario en el cuadrado de la posición, la tasa de disparo se multiplica por <span class="math notranslate nohighlight">\(\exp(\beta_2)=0.99\)</span>.</p>
<p>Expresado de esta manera, los valores de los parámetros <span class="math notranslate nohighlight">\(\beta_1\)</span> y <span class="math notranslate nohighlight">\(\beta_2\)</span> parecen difíciles de interpretar. Una vez que visualizamos este modelo, nos damos cuenta de que hay otra forma de expresar el modelo para que los parámetros sean más fáciles de interpretar:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">spikehist</span> <span class="o">/</span> <span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>    <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">b3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">bins</span> <span class="o">+</span> <span class="n">b3</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">bins</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>  <span class="c1"># Plot model.</span>
     <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">)</span>   
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                      <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4f17ca24db0bd8913bd3aa01e5df3bcad10bd05aac23c2806592c11cafe1d384.png" src="_images/4f17ca24db0bd8913bd3aa01e5df3bcad10bd05aac23c2806592c11cafe1d384.png" />
</div>
</div>
<p>Vemos en la figura anterior que el Modelo 3 se alinea mucho más con el histograma normalizado por ocupación. La tasa de disparo es pequeña al comienzo de la pista, aumenta hasta una tasa de disparo máxima de cerca de 10 Hz a unos 60 cm a lo largo de la pista, y luego disminuye a medida que la posición sigue aumentando. La tasa de disparo modelada como función de la posición se asemeja a la densidad en forma de campana o montículo que a menudo asociamos con la distribución Gaussiana (o normal). El hecho de que la tasa de disparo sea la exponencial de una función cuadrática de la posición significa que podemos reescribir el modelo en una forma que se asemeje más a la función Gaussiana:</p>
<div class="math notranslate nohighlight">
\[
\lambda(t) = \lambda_{\text{max}} \exp\left(-\frac{(x - x_{\text{ctr}})^2}{2\sigma^2}\right)
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\mu=-\beta_1/(2\beta_2)\)</span> es el punto a lo largo de la pista donde la tasa de disparo es máxima (el centro del campo de lugar), <span class="math notranslate nohighlight">\(\sigma=-1/(2\beta_2)\)</span> determina el rango sobre el cual la tasa de disparo está elevada (el tamaño del campo de lugar), y <span class="math notranslate nohighlight">\(\sigma=exp(\beta_0 - \beta_1^2 / (4\beta_2)\)</span> es la tasa de disparo máxima en el centro del campo de lugar.</p>
<p>En este ejemplo, podemos utilizar los coeficientes estimados del GLM para estimar estos nuevos parámetros del modelo relacionados con el centro, tamaño y tasa de disparo máxima del campo de lugar. El método de ajuste nos ha dado las estimaciones de máxima verosimilitud para <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, y <span class="math notranslate nohighlight">\(\beta_2\)</span>. Un resultado importante de la teoría estadística es que la estimación de máxima verosimilitud de cualquier función de los parámetros del modelo es simplemente esa misma función aplicada a las estimaciones de máxima verosimilitud de los parámetros. Esto se conoce comúnmente como invarianza o equivarianza [Kass, Eden &amp; Brown, 2014]. Así que <span class="math notranslate nohighlight">\(\mu=-\beta_1/(2\beta_2)\)</span> es la estimación de máxima verosimilitud del centro del campo de lugar, <span class="math notranslate nohighlight">\(\sigma\)</span> es la estimación de máxima verosimilitud del tamaño del campo de lugar, y así sucesivamente.</p>
<p>Ahora, usemos estas expresiones para calcular las estimaciones de máxima verosimilitud en Python:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Compute maximum likelihood estimates of</span>
<span class="n">mu</span> <span class="o">=</span> <span class="o">-</span><span class="n">b3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b3</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>                  <span class="c1"># place field center</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">b3</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>             <span class="c1"># place field size</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b3</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">b3</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">4</span> <span class="o">/</span> <span class="n">b3</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># max firing rate</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">sigma: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">alpha: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mu: 63.16295780404678
sigma: 9.566890841873345
alpha: 0.011285495199176272
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparacion-y-evaluacion-de-modelos">
<h3>Comparación y evaluación de modelos<a class="headerlink" href="#comparacion-y-evaluacion-de-modelos" title="Permalink to this heading">#</a></h3>
<p>Hemos ajustado varios modelos para el campo receptivo de esta neurona y los hemos comparado a través de inspección visual. Idealmente, nos gustaría ir más allá de las comparaciones cualitativas y considerar herramientas cuantitativas que nos ayuden a evaluar y comparar diferentes modelos. Para los modelos estadísticos, a menudo usamos el término “bondad de ajuste” para describir qué tan bien un modelo captura la estructura en los datos observados y qué tan bien predice datos futuros. No existe un procedimiento único para medir la bondad de ajuste; en cambio, hay muchas herramientas que, en conjunto, pueden proporcionar una perspectiva amplia sobre las fortalezas y debilidades de un conjunto de modelos. Exploramos algunos enfoques para comparar la bondad de ajuste relativa entre dos modelos y luego métodos para evaluar la bondad de ajuste general de un solo modelo.</p>
<section id="metodo-1-comparacion-de-valores-aic">
<h4>Método 1: Comparación de valores AIC<a class="headerlink" href="#metodo-1-comparacion-de-valores-aic" title="Permalink to this heading">#</a></h4>
<p>Supongamos que queremos comparar la calidad del ajuste a los datos de los Modelos 2 y 3. ¿Qué medida podríamos usar para comparar estos modelos? Un pensamiento natural es usar la verosimilitud. Ya hemos utilizado la verosimilitud para seleccionar los valores de los parámetros de cada uno de estos modelos; seleccionamos los parámetros que maximizaron la verosimilitud de los datos. Podemos pensar en la selección de los parámetros del modelo como la selección entre un conjunto de modelos con la misma forma de modelo pero diferentes valores de parámetros. En ese caso, la verosimilitud fue la medida que utilizamos para hacer la selección.</p>
<p>Sin embargo, hay un problema importante al usar solo la verosimilitud para comparar la bondad de ajuste entre diferentes clases de modelos. Resulta que a medida que agregamos parámetros al modelo y lo hacemos más complejo, tendemos a aumentar la verosimilitud de los datos, ya sea que esos términos adicionales describan con precisión los procesos que generan los datos o no. Si seleccionáramos modelos que maximizan la verosimilitud de los datos sin considerar el tamaño del modelo, tenderíamos a obtener modelos muy grandes que se ajustan bien a los datos observados pero que no predicen o describen bien los datos futuros. Esto se conoce como el problema del sobreajuste. Para evitar el sobreajuste, nos vemos obligados a equilibrar la capacidad de ajustar conjuntos de datos complicados con el deseo de utilizar modelos simples con un pequeño número de parámetros. Este compromiso a veces se denomina el objetivo de la parsimonia en la modelización. Queremos ser cuidadosos con el número de parámetros que permitimos que tenga un modelo. Llamamos modelo parsimonioso a un modelo que describe bien los datos con el menor número posible de parámetros.</p>
<p>Un enfoque común para prevenir el sobreajuste es la validación cruzada. Existen múltiples tipos de validación cruzada, pero todos comparten una idea común: dividir los datos en varias porciones, ajustar el modelo en una porción de los datos (llamada conjunto de entrenamiento) y determinar qué tan bien describe el ajuste resultante una porción separada de los datos (llamada conjunto de prueba). Esto asegura que el modelo seleccionado sea uno que pueda generalizar a conjuntos de datos adicionales que no se utilizaron para ajustar el modelo. Un desafío con la validación cruzada es que puede ser computacionalmente costosa. Por ejemplo, uno de los enfoques de validación cruzada más robustos, llamado validación cruzada completa con eliminación de uno, implica omitir secuencialmente cada punto de datos, ajustar un modelo a los datos restantes y evaluar qué tan bien el modelo ajustado predice el punto de datos excluido. Esto implica ajustar <span class="math notranslate nohighlight">\(N\)</span> modelos, donde <span class="math notranslate nohighlight">\(N\)</span> es el número de puntos de datos observados.</p>
<p>Aquí, en lugar de ajustar un gran número de modelos, tomamos otro enfoque, que da resultados equivalentes a la validación cruzada cuando el conjunto de datos es grande. Es decir, utilizamos medidas de verosimilitud penalizada para comparar tipos de modelos. Estas medidas hacen explícito el compromiso entre ajustar bien los datos (aumentando la verosimilitud) y utilizar un pequeño número de parámetros (penalizando los modelos grandes). Consideremos una de estas medidas, el criterio de información de Akaike (AIC). Se define como:</p>
<div class="math notranslate nohighlight">
\[ \text{AIC} = - 2\log{L(\theta_{ML}})+2p \]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{L}\)</span> es la verosimilitud de los datos para la estimación de máxima verosimilitud seleccionada <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>, y <span class="math notranslate nohighlight">\(k\)</span> es el número de parámetros en el modelo. Consideramos el <span class="math notranslate nohighlight">\(2k\)</span> en la expresión como una penalización para modelos con un gran número de parámetros.</p>
<p>Al comparar modelos, calculamos el AIC para cada modelo por separado y luego calculamos la diferencia en AICs entre modelos. Para los modelos que describen con precisión la estructura de los datos, <span class="math notranslate nohighlight">\(\hat{L}\)</span> será alta, y por lo tanto <span class="math notranslate nohighlight">\(-2\log(\hat{L})\)</span> será pequeño. Los modelos parsimoniosos tendrán un pequeño número de parámetros, y por lo tanto <span class="math notranslate nohighlight">\(2k\)</span> será pequeño. Por lo tanto, estamos buscando modelos con valores de AIC lo más pequeños posible.</p>
<p>¿Cómo calculamos la verosimilitud o el logaritmo de la verosimilitud de los datos para los modelos en Python? Una forma es utilizar el hecho de que estamos modelando la secuencia de spikes como una variable aleatoria de Poisson en cada punto en el tiempo con parámetros de tasa determinados por el modelo. Para ver el AIC de un GLM en Python, simplemente podemos usar el atributo <code class="docutils literal notranslate"><span class="pre">aic</span></code> de los resultados del modelo: <code class="docutils literal notranslate"><span class="pre">model2_results.aic</span></code>. Sin embargo, el cálculo no es difícil. Para el Modelo 2, podemos calcular el AIC de la siguiente manera:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LL2</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">loglike</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
<span class="n">AIC2</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">LL2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;AIC2: &#39;</span><span class="p">,</span> <span class="n">AIC2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;model2_results.aic: &#39;</span><span class="p">,</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">aic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AIC2:  3344.790862938608
model2_results.aic:  3344.790862938608
</pre></div>
</div>
</div>
</div>
<p>La primera línea de este código calcula la log-verosimilitud para el Modelo 2. Recordemos que la verosimilitud es la distribución conjunta de todos los datos para un modelo específico. En este caso, el número de spikes en cada intervalo se modela como una variable aleatoria de Poisson con tasa <span class="math notranslate nohighlight">\(\lambda(t)\)</span>. Por lo tanto, la log-verosimilitud (<span class="math notranslate nohighlight">\(\text{LL}_2\)</span>) es el logaritmo del producto de los valores de probabilidad de Poisson para los spikes observados bajo el modelo propuesto (o equivalentemente, la suma del logaritmo de estos valores de probabilidad de Poisson). La segunda línea calcula el AIC para este modelo. Observa que usamos un valor de <span class="math notranslate nohighlight">\(p = 2\)</span>, ya que hay dos parámetros en este modelo (<span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span>). Por último, mostramos que, efectivamente, esto es lo mismo que resulta al acceder al atributo <code class="docutils literal notranslate"><span class="pre">aic</span></code> de los resultados del modelo.</p>
<p>De manera similar, podemos calcular el AIC para el Modelo 3:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LL3</span> <span class="o">=</span> <span class="n">model3</span><span class="o">.</span><span class="n">loglike</span><span class="p">(</span><span class="n">b3</span><span class="p">)</span>
<span class="n">AIC3</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">LL3</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">3</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;AIC3: &#39;</span><span class="p">,</span> <span class="n">AIC3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AIC3:  2708.776362292046
</pre></div>
</div>
</div>
</div>
<p>Encontramos un valor de <span class="math notranslate nohighlight">\(dAIC = 636.0145\)</span>. Esta diferencia indica que el AIC del Modelo 3 es menor que el del Modelo 2, lo que sugiere que el Modelo 3 es superior. ¿Cómo deberíamos interpretar el valor de esta diferencia? La respuesta depende del modelo probabilístico que estemos utilizando, y generalmente solo nos interesa cuál modelo tiene el AIC más bajo sin preocuparnos por la magnitud de la diferencia. Sin embargo, una forma aproximada de pensar en este valor es en términos de la penalización. El hecho de que el Modelo 3 tenga un AIC de aproximadamente 636 menos que el AIC del Modelo 2 sugiere que el Modelo 3 seguiría siendo preferible al Modelo 2 incluso si el Modelo 3 tuviera 636/2 = 318 parámetros más de los que tiene actualmente.</p>
<p>Resulta que hay una forma más sencilla de calcular la diferencia en los AIC entre dos GLMs. Cada vez que Python (y la mayoría de los otros paquetes de software computacional) calcula la solución de máxima verosimilitud para un GLM, también calcula la devianza del modelo. La devianza del modelo es una medida de la falta de ajuste entre el modelo y los datos, que se define por</p>
<div class="math notranslate nohighlight">
\[
\text{Deviance} = -2 \text{Log}L(\theta_{ML}) + C)
\]</div>
<p>donde <span class="math notranslate nohighlight">\(C\)</span> es una constante. Por lo tanto, la diferencia en los valores de AIC entre dos modelos se puede calcular como</p>
<div class="math notranslate nohighlight">
\[
\Delta AIC = \text{AIC}_1 - \text{AIC}_2 =Dev_1 + 2p_1-Dev=2+2p_2
\]</div>
<p>donde <span class="math notranslate nohighlight">\(AIC_1\)</span>, <span class="math notranslate nohighlight">\(Dev_1\)</span> y <span class="math notranslate nohighlight">\(p_1\)</span> son el AIC, devianza y número de parámetros para el primer modelo, y <span class="math notranslate nohighlight">\(AIC_2\)</span>, <span class="math notranslate nohighlight">\(Dev_2\)</span> y <span class="math notranslate nohighlight">\(p_2\)</span> son el AIC, devianza y número de parámetros para el segundo modelo. La constante <span class="math notranslate nohighlight">\(C\)</span> se cancela al calcular la diferencia en los valores de AIC.</p>
<p>En Python, podemos calcular los valores para la devianza y la diferencia en AIC de la siguiente manera:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dev2</span> <span class="o">=</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">deviance</span> <span class="c1"># Deviance from model 2</span>
<span class="n">dev3</span> <span class="o">=</span> <span class="n">model3_results</span><span class="o">.</span><span class="n">deviance</span> <span class="c1"># Deviance from model 3</span>
<span class="n">dAIC</span> <span class="o">=</span> <span class="p">(</span><span class="n">dev2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">dev3</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dAIC: &#39;</span><span class="p">,</span> <span class="n">dAIC</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Another method: &#39;</span><span class="p">,</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">aic</span> <span class="o">-</span> <span class="n">model3_results</span><span class="o">.</span><span class="n">aic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dAIC:  636.0145006465614
Another method:  636.0145006465618
</pre></div>
</div>
</div>
</div>
</section>
<section id="metodo-2-prueba-de-chi-cuadrado-para-modelos-anidados">
<h4>Método 2: Prueba de Chi-Cuadrado para Modelos Anidados.<a class="headerlink" href="#metodo-2-prueba-de-chi-cuadrado-para-modelos-anidados" title="Permalink to this heading">#</a></h4>
<p>El AIC proporciona un método para identificar modelos parsimoniosos y comparar entre modelos, pero por sí solo no indica si un modelo en particular proporciona una mejora estadísticamente significativa en su descripción de un conjunto de datos. Por ejemplo, podríamos agregar un predictor a un modelo que no tiene ninguna relación real con los datos observados y, sin embargo, disminuir el AIC por casualidad. Para evaluar si un modelo proporciona una mejora significativa sobre otro, podemos usar pruebas de hipótesis basadas en las verosimilitudes de los modelos.</p>
<p>En particular, existe una clase general de pruebas de hipótesis llamadas pruebas de razón de verosimilitud máxima (MLRTs) que a menudo proporcionan la comparación estadística más poderosa entre modelos. En general, puede ser difícil calcular la estadística de prueba y su distribución muestral para las MLRTs. Sin embargo, se vuelve fácil realizar esta prueba en casos donde estamos comparando dos GLMs anidados, es decir, cuando uno de los modelos puede hacerse equivalente al otro al fijar algunos parámetros en valores específicos. Por ejemplo, es posible hacer que el Modelo 3 sea equivalente al Modelo 2 fijando <span class="math notranslate nohighlight">\(\beta_2 = 0\)</span>. Decimos que el Modelo 2 está anidado en el Modelo 3. Sin embargo, no hay forma de fijar parámetros para hacer que el Modelo 2 sea equivalente al Modelo 1 o viceversa, por lo que estos modelos no están anidados. Se puede demostrar que cuando comparamos dos GLMs de Poisson anidados para datos de trenes de espigas, la MLRT será asintóticamente una simple prueba de chi-cuadrado (<span class="math notranslate nohighlight">\(\chi^2\)</span>). La demostración de este resultado se puede encontrar en muchos libros de texto sobre GLMs, como <em>McCullagh &amp; Nelder, 1989</em>.</p>
<p>Especifiquemos los componentes de esta prueba de hipótesis. Supongamos que el modelo anidado tiene <span class="math notranslate nohighlight">\(n_1\)</span> parámetros <span class="math notranslate nohighlight">\(\theta_{n1}\)</span>, y que el modelo más grande tiene <span class="math notranslate nohighlight">\(n_2\)</span> parámetros, <span class="math notranslate nohighlight">\(\beta_{n2}\)</span>. La hipótesis nula para esta prueba es <span class="math notranslate nohighlight">\(H_0: \beta_{n1+1}=...=\beta{n2}= 0\)</span>, que todos los parámetros adicionales no contenidos en el modelo anidado son iguales a cero. La hipótesis alternativa es que al menos uno de estos parámetros adicionales es diferente de cero. La estadística de prueba para esta MLRT es equivalente a la diferencia en las desviaciones entre el modelo anidado (aquí, <span class="math notranslate nohighlight">\(\text{Deviance}_1\)</span>) y el modelo más grande (aquí, <span class="math notranslate nohighlight">\(\text{Dev}_2\)</span>),</p>
<div class="math notranslate nohighlight">
\[
\chi^2 = \text{Deviance}_1 - \text{Deviance}_2
\]</div>
<p>Bajo la hipótesis nula, esta estadística debería tener asintóticamente una distribución chi-cuadrado con <span class="math notranslate nohighlight">\(n_2-n_1\)</span> grados de libertad. Podemos calcular el valor p para una prueba que compare dos GLMs anidados para datos de trenes de espigas utilizando el objeto <code class="docutils literal notranslate"><span class="pre">chi2</span></code> en el módulo <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> de Python.</p>
<p>Vamos a calcular el valor p para una MLRT que compare los Modelos 2 y 3:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">chi2</span>  <span class="c1"># Importar chi2 desde scipy.stats</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">dev2</span> <span class="o">-</span> <span class="n">dev3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Compare Models 2 and 3, nested GLMs.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;p:&#39;</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p: 0.0
</pre></div>
</div>
</div>
</div>
<p>En este caso, la diferencia en los parámetros entre el Modelo 2 y el Modelo 3 es 1; el Modelo 3 tiene un parámetro adicional. Por lo tanto, establecemos los grados de libertad de la distribución chi-cuadrado en 1, el segundo argumento de la función <code class="docutils literal notranslate"><span class="pre">chi2.cdf()</span></code>. Encontramos que el valor p calculado es cero, con la precisión que Python es capaz de calcular la distribución chi-cuadrado. En la práctica, esto significa que el valor p para esta prueba no es exactamente cero, pero es menor que aproximadamente <span class="math notranslate nohighlight">\(2.2 \times 10^{-16}\)</span> (ver <a class="reference external" href="https://docs.python.org/3/tutorial/floatingpoint.html">aquí</a> para una discusión sobre la epsilon de la máquina en Python). Tenemos una gran cantidad de evidencia de que el parámetro cuadrático adicional en el Modelo 3, <span class="math notranslate nohighlight">\(\beta_2\)</span>, es distinto de cero.</p>
</section>
<section id="metodo-3-intervalos-de-confianza-para-parametros-individuales-del-modelo">
<h4>Método 3: Intervalos de Confianza para Parámetros Individuales del Modelo.<a class="headerlink" href="#metodo-3-intervalos-de-confianza-para-parametros-individuales-del-modelo" title="Permalink to this heading">#</a></h4>
<p>Si queremos probar directamente si un parámetro contribuye significativamente al modelo, podemos examinar su estimación de intervalo. El procedimiento de ajuste del GLM no solo calcula el estimador de máxima verosimilitud para cada parámetro del modelo, sino que también calcula la información de Fisher, una cantidad relacionada con la curvatura de la verosimilitud, que puede usarse para calcular intervalos de confianza sobre cualquier parámetro individual o cualquier combinación de parámetros. No discutimos la información de Fisher en detalle aquí (para más información, ver <em>Kass, Eden &amp; Brown, 2014</em>), pero la idea básica es intuitiva. Si la verosimilitud es muy plana en su máximo, entonces cambiar ligeramente los valores de los parámetros no disminuirá sustancialmente la verosimilitud. Por lo tanto, existe un rango potencialmente amplio de valores de parámetros que podrían hacer que los datos sean probables. Si la verosimilitud es muy pronunciada en su máximo, entonces un ligero cambio en los valores de los parámetros causaría un gran cambio en la verosimilitud, y por lo tanto un rango mucho más estrecho de valores de parámetros sería consistente con los datos.</p>
<p>La clase <code class="docutils literal notranslate"><span class="pre">GLMResults</span></code> contiene una variedad de atributos útiles. Dos componentes que son útiles para examinar la significancia de los parámetros individuales del modelo son <code class="docutils literal notranslate"><span class="pre">bse</span></code> y <code class="docutils literal notranslate"><span class="pre">pvalues</span></code>. El primero, <code class="docutils literal notranslate"><span class="pre">bse</span></code>, proporciona el error estándar de cada estimación de parámetro. Dado que los estimadores de máxima verosimilitud tienen distribuciones aproximadamente normales con suficiente cantidad de datos, un intervalo de confianza aproximado del 95% para cualquier parámetro <span class="math notranslate nohighlight">\(\beta_j\)</span> sería <span class="math notranslate nohighlight">\(\hat{\beta_j} \pm 1.96 \cdot SE(\hat{\beta_j})\)</span>, donde <span class="math notranslate nohighlight">\(\hat{\beta_j}\)</span> es la estimación del parámetro y <span class="math notranslate nohighlight">\(SE(\hat{\beta_j})\)</span> es el error estándar estimado.</p>
<p>Vamos ahora a usar el atributo <code class="docutils literal notranslate"><span class="pre">bse</span></code> para calcular intervalos de confianza para los parámetros del Modelo 2:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CI2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">bse</span><span class="p">,</span> <span class="n">b2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">bse</span><span class="p">])</span> <span class="c1"># Compute 95% CI for parameters of Model 2.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CI2:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">CI2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CI2:
 [[-7.73444907  0.00892032]
 [-7.14332531  0.01696651]]
</pre></div>
</div>
</div>
</div>
<p>La columna izquierda de la variable <code class="docutils literal notranslate"><span class="pre">CI2</span></code> es el intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_0\)</span>, y la columna derecha es el intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_1\)</span>. ¿Cómo deberíamos interpretar estos intervalos de confianza? Al igual que antes, serán más interpretables si los exponenciamos primero.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eCI2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">CI2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">eCI2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[4.37493342e-04 1.00896023e+00]
 [7.90120328e-04 1.01711126e+00]]
</pre></div>
</div>
</div>
</div>
<p>El intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_0\)</span> describe la incertidumbre en la tasa de disparo en la posición <span class="math notranslate nohighlight">\(x = 0\)</span>. En esa posición, estamos al 95% seguros de que la tasa está entre 0.0004 y 0.0008 (la columna izquierda de <code class="docutils literal notranslate"><span class="pre">eCI2</span></code>) disparos por milisegundo, o entre 0.4 y 0.8 disparos por segundo. El intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_1\)</span> describe la incertidumbre en el efecto de un cambio unitario en la posición sobre la tasa de disparo. Cada vez que incrementamos <span class="math notranslate nohighlight">\(\beta_1\)</span> en 1, la tasa se modula por un valor entre 1.009 y 1.0171 (la segunda columna de <code class="docutils literal notranslate"><span class="pre">eCI2</span></code>). En otras palabras, cada incremento de 1 cm en la posición aumenta la tasa de disparo entre aproximadamente 0.9% y 1.7%.</p>
<p>Otro uso de los intervalos de confianza es expresar la significancia estadística de los parámetros individuales dentro del modelo. Si el valor verdadero de un parámetro es cero, entonces la covariable correspondiente a ese parámetro no contribuye a la predicción de los datos en el GLM. Si computamos un intervalo de confianza para un parámetro y no contiene cero, tenemos evidencia suficiente (al nivel de confianza utilizado para construir el intervalo) de que el valor verdadero del parámetro difiere de cero, y que la covariable para ese parámetro tiene una contribución significativa dentro del GLM. Podemos usar esto nuevamente para determinar si la adición del término cuadrático en el Modelo 3 proporciona una mejora significativa sobre el Modelo 2. Para hacerlo, utilicemos las variables de salida calculadas <code class="docutils literal notranslate"><span class="pre">b3</span></code> y <code class="docutils literal notranslate"><span class="pre">bse</span></code> para el Modelo 3 para determinar los intervalos de confianza para cada parámetro en el Modelo 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CI3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b3</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">model3_results</span><span class="o">.</span><span class="n">bse</span><span class="p">,</span> 
            <span class="n">b3</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">model3_results</span><span class="o">.</span><span class="n">bse</span><span class="p">])</span> <span class="c1"># Compute 95% CI for parameters of Model 3.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">CI3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[-2.99542831e+01  5.77810706e-01 -6.30948487e-03]
 [-2.26038307e+01  8.02417242e-01 -4.61644384e-03]]
</pre></div>
</div>
</div>
</div>
<p>La variable resultante <code class="docutils literal notranslate"><span class="pre">CI3</span></code> consta de tres columnas. La columna más a la derecha es el intervalo de confianza para <span class="math notranslate nohighlight">\(\beta_2\)</span>. Vemos que este intervalo (<code class="docutils literal notranslate"><span class="pre">CI3[:,2]=[-0.0063</span> <span class="pre">-0.0046]</span></code>) no contiene cero, por lo que el término cuadrático es significativo al nivel de confianza del 95%.</p>
<p>¿Qué tan significativo es este término? Para responder a esto, podemos realizar una prueba de hipótesis para determinar si <span class="math notranslate nohighlight">\(\beta_2\)</span> es diferente de cero. Esta prueba, basada en la estimación de máxima verosimilitud de un parámetro del modelo y su error estándar, se llama prueba de Wald. El nivel de significancia de esta prueba se da por el atributo <code class="docutils literal notranslate"><span class="pre">pvalues</span></code> de la clase <code class="docutils literal notranslate"><span class="pre">GLMResults</span></code>. Para el Modelo 3, el nivel de significancia para el parámetro <span class="math notranslate nohighlight">\(\beta_2\)</span> es</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p_beta2</span> <span class="o">=</span> <span class="n">model3_results</span><span class="o">.</span><span class="n">pvalues</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">p_beta2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.117080430548911e-38
</pre></div>
</div>
</div>
</div>
<p>Encontramos <span class="math notranslate nohighlight">\(p_{\beta_2} = 4.12 \times 10^{-38}\)</span>, que es muy cercano a cero. Este resultado es consistente con nuestro hallazgo previo, a través del MLRT, de que la mejora del Modelo 3 sobre el Modelo 2 sugiere que el componente cuadrático del modelo era significativo a un nivel de <span class="math notranslate nohighlight">\(p\)</span> de <span class="math notranslate nohighlight">\(&lt; 10^{-5}\)</span>.</p>
</section>
</section>
<section id="poisson-en-r">
<h3>Poisson en R<a class="headerlink" href="#poisson-en-r" title="Permalink to this heading">#</a></h3>
<p>A continuación se presenta un ejemplo de Poisson homogeneo en R. Este conjunto de datos analiza cuántas roturas de urdimbre ocurrieron en diferentes tipos de telares por telar, por una longitud fija de hilo.</p>
<p>Hay mediciones en 9 telares de cada uno de los seis tipos de urdimbre, para un total de 54 entradas en el conjunto de datos.</p>
<p>Veamos cómo está estructurado el conjunto de datos usando el comando <code class="docutils literal notranslate"><span class="pre">ls.str()</span></code>:</p>
<p>A partir de lo anterior, podemos ver tanto los tipos como los niveles presentes en los datos. Lee esto para aprender un poco más sobre los factores en R.</p>
<p>Ahora trabajaremos con el dataframe de datos. Recuerda, con un modelo de Distribución de Poisson estamos tratando de averiguar cómo algunas variables predictoras afectan a una variable de respuesta. Aquí, <code class="docutils literal notranslate"><span class="pre">breaks</span></code> es la variable de respuesta y <code class="docutils literal notranslate"><span class="pre">wool</span></code> y <code class="docutils literal notranslate"><span class="pre">tension</span></code> son las variables predictoras.</p>
<p>Podemos visualizar la continuidad de los datos de la variable dependiente <code class="docutils literal notranslate"><span class="pre">breaks</span></code> creando un histograma:</p>
<p>Claramente, los datos no tienen la forma de una curva de campana como en una distribución normal.</p>
<p>Veamos la media (<code class="docutils literal notranslate"><span class="pre">mean()</span></code>) y la varianza (<code class="docutils literal notranslate"><span class="pre">var()</span></code>) de la variable dependiente:</p>
<p>La varianza es mucho mayor que la media, lo que sugiere que tendremos sobredispersión en el modelo.</p>
<p>Vamos a ajustar el modelo de Poisson utilizando el comando <code class="docutils literal notranslate"><span class="pre">glm()</span></code>.</p>
<p>Se nos ha proporcionado mucha información, ahora necesitamos interpretarla. La primera columna llamada <em>Estimate</em> muestra los valores de los coeficientes de <span class="math notranslate nohighlight">\(\alpha\)</span> (intercepto), <span class="math notranslate nohighlight">\(\beta_1\)</span>, y así sucesivamente. A continuación, se presenta la interpretación de las estimaciones de los parámetros:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(exp(\alpha) =\)</span> efecto sobre la media <span class="math notranslate nohighlight">\(\mu\)</span>, cuando <span class="math notranslate nohighlight">\(X = 0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(exp(\beta) =\)</span> con cada aumento unitario en <span class="math notranslate nohighlight">\(X\)</span>, la variable predictora tiene un efecto multiplicativo de <span class="math notranslate nohighlight">\(exp(\beta)\)</span> sobre la media de <span class="math notranslate nohighlight">\(Y\)</span>, es decir, <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\beta = 0\)</span>, entonces <span class="math notranslate nohighlight">\(exp(\beta) = 1\)</span>, y el conteo esperado es <span class="math notranslate nohighlight">\(exp(\alpha)\)</span>, y <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(X\)</span> no están relacionados.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\beta &gt; 0\)</span>, entonces <span class="math notranslate nohighlight">\(exp(\beta) &gt; 1\)</span>, y el conteo esperado es <span class="math notranslate nohighlight">\(exp(\beta)\)</span> veces mayor que cuando <span class="math notranslate nohighlight">\(X = 0\)</span>.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(\beta &lt; 0\)</span>, entonces <span class="math notranslate nohighlight">\(exp(\beta) &lt; 1\)</span>, y el conteo esperado es <span class="math notranslate nohighlight">\(exp(\beta)\)</span> veces menor que cuando <span class="math notranslate nohighlight">\(X = 0\)</span>.</p></li>
</ul>
<p>Si <code class="docutils literal notranslate"><span class="pre">family</span> <span class="pre">=</span> <span class="pre">poisson</span></code> se mantiene en <code class="docutils literal notranslate"><span class="pre">glm()</span></code>, estos parámetros se calculan utilizando la Estimación de Máxima Verosimilitud (MLE).</p>
<p>R trata las variables categóricas como variables ficticias (<em>dummy variables</em>). Las variables categóricas, también llamadas variables indicadoras, se convierten en variables ficticias asignando a los niveles en la variable una representación numérica. La regla general es que si hay <span class="math notranslate nohighlight">\(k\)</span> categorías en una variable de factor, la salida de <code class="docutils literal notranslate"><span class="pre">glm()</span></code> tendrá <span class="math notranslate nohighlight">\(k-1\)</span> categorías con 1 restante como categoría base.</p>
<p>Podemos ver en el resumen anterior que para <code class="docutils literal notranslate"><span class="pre">wool</span></code>, ‘A’ se ha hecho la base y no se muestra en el resumen. De manera similar, para <code class="docutils literal notranslate"><span class="pre">tension</span></code> ‘L’ se ha hecho la categoría base.</p>
<p>Para ver qué variables explicativas tienen un efecto sobre la variable de respuesta, observaremos los valores <em>p</em>. Si el <em>p</em> es menor que 0.05, entonces la variable tiene un efecto sobre la variable de respuesta. En el resumen anterior, podemos ver que todos los valores <em>p</em> son menores que 0.05, por lo tanto, ambas variables explicativas (<code class="docutils literal notranslate"><span class="pre">wool</span></code> y <code class="docutils literal notranslate"><span class="pre">tension</span></code>) tienen un efecto significativo en <code class="docutils literal notranslate"><span class="pre">breaks</span></code>. Observa cómo la salida de R utiliza *** al final de cada variable. El número de estrellas indica la significancia.</p>
<p>Antes de comenzar a interpretar los resultados, verifiquemos si el modelo tiene sobredispersión o subdispersión. Si la Desviación Residual es mayor que los grados de libertad, entonces existe sobredispersión. Esto significa que las estimaciones son correctas, pero los errores estándar (desviación estándar) son incorrectos y no son tenidos en cuenta por el modelo.</p>
<p>La desviación nula (<em>Null deviance</em>) muestra qué tan bien la variable de respuesta es predicha por un modelo que incluye solo el intercepto (media general), mientras que la residual lo hace con la inclusión de variables independientes. Arriba, podemos ver que la adición de 3 (53-50 =3) variables independientes disminuyó la desviación a 210.39 desde 297.37. Una mayor diferencia en los valores significa un mal ajuste.</p>
<p>Entonces, para tener un error estándar más correcto, podemos usar un modelo <em>quasi-poisson</em>.</p>
<p>Una vez que se ha creado el modelo, podemos usar <code class="docutils literal notranslate"><span class="pre">predict(model,</span> <span class="pre">data,</span> <span class="pre">type)</span></code> para predecir resultados utilizando nuevos <em>dataframes</em> que contengan datos diferentes a los datos de entrenamiento. Veamos un ejemplo.</p>
<p><em>jtools</em> proporciona <code class="docutils literal notranslate"><span class="pre">plot_summs()</span></code> y <code class="docutils literal notranslate"><span class="pre">plot_coefs()</span></code> para visualizar el resumen del modelo y también nos permite comparar diferentes modelos con <em>ggplot2</em>.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="03_PointPattern.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Patrón de puntos</p>
      </div>
    </a>
    <a class="right-next"
       href="05_LGCP.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Procesos Log-Gaussian Cox</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-homogeneo">Poisson Homogeneo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ajuste-de-un-modelo-glm-de-poisson">Ajuste de un modelo GLM de Poisson</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-y-evaluacion-de-modelos">Comparación y evaluación de modelos</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-1-comparacion-de-valores-aic">Método 1: Comparación de valores AIC</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-2-prueba-de-chi-cuadrado-para-modelos-anidados">Método 2: Prueba de Chi-Cuadrado para Modelos Anidados.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metodo-3-intervalos-de-confianza-para-parametros-individuales-del-modelo">Método 3: Intervalos de Confianza para Parámetros Individuales del Modelo.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#poisson-en-r">Poisson en R</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Edier V. Aristizábal G.
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>


<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Modelos Lineales Generalizados (GML) &#8212; Análisis Geoespacial</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '04_GLMPhyton';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Visualización de datos discretos" href="06_Coropleta.html" />
    <link rel="prev" title="Patrón de puntos" href="03_PointPattern.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Análisis Geoespacial - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Análisis Geoespacial - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    <no title>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00_Ambiente.html">Ambiente computacional</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_DatosEspaciales.html">Análisis Geoespacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_Mapping.html">El arte de hacer mapas</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_PointPattern.html">Patrón de puntos</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Modelos Lineales Generalizados (GML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_Coropleta.html">Visualización de datos discretos</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_MatrizCorrelacion.html">Matriz espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_ClusterEspacial.html">Cluster espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_SpatialRegression.html">Regresión Espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_SAR.html">Modelos de regresión para dependencia espacial tipo SAR</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_CAR.html">Modelos de regresión para dependencia espacial tipo CAR</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_Jerarquicos.html">Modelos de Regresión para Heterogeneidad Espacial</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_MGWR.html">Regresión Ponderada Geográficamente (GWR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="14_Kriging.html">Kriging con Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="15_GP.html">Procesos Gaussianos con Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="16_GP.html">Procesos Gaussianos con R</a></li>
<li class="toctree-l1"><a class="reference internal" href="17_LGCP.html">Modelo GLM de Poisson no-homogéneo</a></li>
<li class="toctree-l1"><a class="reference internal" href="18_DB.html">Bases de datos geoespaciales</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/edieraristizabal/Libro_AnalisisGeoespacial" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/edieraristizabal/Libro_AnalisisGeoespacial/issues/new?title=Issue%20on%20page%20%2F04_GLMPhyton.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/04_GLMPhyton.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Modelos Lineales Generalizados (GML)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-regresion-logistica">Modelo de Regresión Logística</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-con-statsmodels">Ejemplo con Statsmodels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-con-sklearn">Ejemplo con Sklearn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-poisson">Modelo de Poisson</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-1-de-un-glm-de-poisson-homogeneo">Ejemplo 1 de un GLM de Poisson homogéneo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-2-de-un-glm-de-poisson-homogeneo">Ejemplo 2 de un GLM de Poisson homogéneo</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-binomial-negativo">Modelo Binomial Negativo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo">Ejemplo</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-ceros-inflados">Modelo de Ceros Inflados</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Ejemplo</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p style="font-size:11px;"><em><strong>Créditos</strong>: El contenido de este cuaderno ha sido tomado de varias fuentes, pero especialmente de <a href="https://github.com/Mark-Kramer/Case-Studies-Python/blob/master/09.ipynb">Mar Kramer</a> y <a href="https://stats.oarc.ucla.edu/r/dae/poisson-regression/">UCLA</a>. El compilador se disculpa por cualquier omisión involuntaria y estaría encantado de agregar un reconocimiento.</em></p><section class="tex2jax_ignore mathjax_ignore" id="modelos-lineales-generalizados-gml">
<h1>Modelos Lineales Generalizados (GML)<a class="headerlink" href="#modelos-lineales-generalizados-gml" title="Permalink to this heading">#</a></h1>
<p>Los Modelos Lineales Generalizados (GLM) son una extensión de los modelos lineales clásicos (como la regresión lineal) que permiten modelar una variedad más amplia de tipos de datos, incluyendo aquellos que no siguen una distribución normal. Estos modelos son especialmente útiles cuando la variable dependiente sigue una distribución distinta, como una distribución binomial (en el caso de variables de respuesta dicotómicas), una distribución de Poisson (para conteos), o una distribución gamma (para variables continuas positivas).</p>
<p>Un GLM está compuesto por tres elementos esenciales:</p>
<ul class="simple">
<li><p>Función de enlace (𝑔(⋅)): Establece la relación entre la media de la variable dependiente 𝑌 y los predictores lineales.</p></li>
<li><p>Distribución de la variable dependiente: La variable dependiente 𝑌 sigue una distribución dentro de la familia exponencial (por ejemplo, normal, binomial, Poisson, etc.).</p></li>
<li><p>Predictores lineales: La relación entre los predictores 𝑋1,𝑋2,…,𝑋𝑝 y la variable dependiente se describe mediante una combinación lineal de los mismos.</p></li>
</ul>
<p>La forma general de un GLM se puede expresar como:</p>
<p><span class="math notranslate nohighlight">\(
g(\mathbb{E}[Y_i]) = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \dots + \beta_p X_{ip}
\)</span></p>
<p>Donde:</p>
<ul class="simple">
<li><p>𝑌𝑖 es la variable dependiente para la 𝑖-ésima observación.</p></li>
<li><p>𝑔(𝐸[𝑌𝑖]) es la función de enlace aplicada a la esperanza de 𝑌𝑖.</p></li>
<li><p>𝛽0 es el intercepto y 𝛽1,𝛽2,…𝛽𝑝 son los coeficientes de los predictores 𝑋1,𝑋2,…,𝑋𝑝.</p></li>
<li><p>𝑔(⋅) es la función de enlace, que transforma la media de 𝑌𝑖 en un valor que tiene una forma lineal respecto a los predictores.</p></li>
</ul>
<p>Dependiendo del tipo de variable dependiente, se utilizan diferentes distribuciones dentro de la familia exponencial:</p>
<section id="modelo-de-regresion-logistica">
<h2>Modelo de Regresión Logística<a class="headerlink" href="#modelo-de-regresion-logistica" title="Permalink to this heading">#</a></h2>
<p>La regresión logística es un modelo lineal generalizado (GLM, por sus siglas en inglés) utilizado para modelar variables respuesta binarias. A diferencia de la regresión lineal clásica, donde la variable dependiente es continua, en la regresión logística la respuesta 𝑌 toma únicamente dos valores posibles, usualmente codificados como 0 y 1. Este método es ampliamente utilizado en análisis de eventos geoespaciales, como la ocurrencia o no de deslizamientos, incendios, inundaciones, entre otros.</p>
<p>Mientras la regresión binomial modela proporciones o conteos de éxitos en un número fijo de ensayos 𝑛, la regresión logística corresponde a un caso especial del modelo binomial con 𝑛=1.</p>
<p>La función de distribución acumulada de la distribución logística está definida como:</p>
<div class="math notranslate nohighlight">
\[
F(x; \mu, s) = \frac{1}{1 + \exp\left(-\frac{x - \mu}{s}\right)}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(( x \in \mathbb{R})\)</span> es la variable aleatoria continua,</p></li>
<li><p><span class="math notranslate nohighlight">\(( \mu \in \mathbb{R})\)</span> es el parámetro de <strong>ubicación</strong> (media y punto de inflexión),</p></li>
<li><p><span class="math notranslate nohighlight">\(( s &gt; 0 )\)</span> es el parámetro de <strong>escala</strong>, que determina la pendiente o dispersión de la curva.</p></li>
</ul>
<p>Esta función tiene forma de sigmoide y es la base del modelo de regresión logística. El valor de <span class="math notranslate nohighlight">\(( F(x; \mu, s) )\)</span> representa la probabilidad acumulada hasta el punto <span class="math notranslate nohighlight">\(( x )\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">logistic</span>

<span class="c1"># Rango de valores de x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Conjuntos de parámetros (mu, s)</span>
<span class="n">param_sets</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>     <span class="c1"># estándar</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>   <span class="c1"># más empinada</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>     <span class="c1"># más dispersa</span>
    <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>    <span class="c1"># desplazada a la izquierda</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>     <span class="c1"># desplazada a la derecha</span>
<span class="p">]</span>

<span class="c1"># Colores para la visualización</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">]</span>

<span class="c1"># Graficar CDF para cada conjunto de parámetros</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">s</span><span class="p">),</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">param_sets</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$\mu=</span><span class="si">{</span><span class="n">mu</span><span class="si">}</span><span class="s1">,\ s=</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Funciones de distribución logística (CDF) con diferentes parámetros&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$F(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c3557ac28b6569d9990620691749d55f74ea6e11817c021708f0fa76f33635f3.png" src="_images/c3557ac28b6569d9990620691749d55f74ea6e11817c021708f0fa76f33635f3.png" />
</div>
</div>
<p>Cuando 𝑠 disminuye (por ejemplo,𝑠=0.5), la curva se vuelve más empinada: los cambios en 𝑥 producen variaciones más abruptas en la probabilidad.</p>
<p>Cuando 𝑠 aumenta (por ejemplo, 𝑠=2), la curva se aplana: los cambios en 𝑥 tienen menor impacto inmediato en la probabilidad.</p>
<p>Cuando 𝜇 se desplaza (por ejemplo, 𝜇=−3 o 𝜇=3), se mueve el punto de inflexión de la sigmoide hacia la izquierda o derecha, sin cambiar la forma de la curva.</p>
<p>Sea <span class="math notranslate nohighlight">\(Y_i \in \{0,1\}\)</span> una variable aleatoria binaria que representa la ocurrencia de un evento en la unidad <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Se modela la probabilidad condicional <span class="math notranslate nohighlight">\(\pi_i = \mathbb{P}(Y_i = 1 \mid \mathbf{x}_i)\)</span> como:</p>
<div class="math notranslate nohighlight">
\[
\pi_i = \frac{1}{1 + \exp(-\eta_i)} = \text{logit}^{-1}(\eta_i)
\]</div>
<p>donde el predictor lineal es:</p>
<div class="math notranslate nohighlight">
\[
\eta_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \dots + \beta_p x_{ip} = \mathbf{x}_i^\top \boldsymbol{\beta}
\]</div>
<p>y la función de enlace logit es:</p>
<div class="math notranslate nohighlight">
\[
\text{logit}(\pi_i) = \log\left(\frac{\pi_i}{1 - \pi_i}\right) = \eta_i
\]</div>
<p>El modelo asume una distribución Bernoulli para la respuesta:</p>
<div class="math notranslate nohighlight">
\[
Y_i \sim \text{Bernoulli}(\pi_i)
\]</div>
<p>La función log-verosimilitud para los <span class="math notranslate nohighlight">\(n\)</span> datos observados es:</p>
<div class="math notranslate nohighlight">
\[
\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[ y_i \log(\pi_i) + (1 - y_i)\log(1 - \pi_i) \right]
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\pi_i = \frac{1}{1 + \exp(-\mathbf{x}_i^\top \boldsymbol{\beta})}\)</span>.</p>
<p>Cada coeficiente 𝛽𝑗 se interpreta como el cambio en el logit (log-odds) de la probabilidad de éxito por unidad de incremento en 𝑥𝑗, manteniendo las demás variables constantes. Alternativamente, exp(𝛽𝑗) representa el odds ratio, es decir, el factor multiplicativo en las probabilidades al incrementar en una unidad
𝑥𝑗.
$<span class="math notranslate nohighlight">\(
\frac{\partial \log\left( \frac{\pi_i}{1 - \pi_i} \right)}{\partial x_j} = \beta_j
\)</span>$</p>
<p>Y el <strong>odds ratio</strong> se obtiene como:</p>
<div class="math notranslate nohighlight">
\[
\text{OR}_j = \exp(\beta_j)
\]</div>
<p>Como ventajas se tiene:</p>
<ul class="simple">
<li><p>Flexibilidad: Permite modelar probabilidades entre 0 y 1 mediante una función sigmoide.</p></li>
<li><p>Interpretabilidad: Los odds ratios son intuitivos y útiles para la toma de decisiones.</p></li>
<li><p>Ampliamente implementado: Disponible en casi todos los lenguajes estadísticos (R, Python, STATA, etc.).</p></li>
<li><p>Generalizable: Es un caso particular del marco de los modelos lineales generalizados, lo que permite su extensión a modelos multivariados, espaciales y jerárquicos.</p></li>
</ul>
<p>Como desventajas se registran:</p>
<ul class="simple">
<li><p>No modela directamente la probabilidad si hay correlación espacial o temporal, lo cual puede llevar a errores de inferencia.</p></li>
<li><p>Sensibilidad a valores atípicos: Aunque más robusta que la regresión lineal, sigue siendo afectada por outliers en las covariables.</p></li>
<li><p>Supone independencia: No es adecuada si hay dependencia espacial o temporal entre las observaciones, lo cual es común en datos geoespaciales.</p></li>
<li><p>Relación lineal en el logit: Si la relación real no es lineal en el logit, el modelo puede no ajustarse bien.</p></li>
</ul>
<p>Sin embargo, debido a la naturaleza espacial de estos fenómenos, es frecuente combinar la regresión logística con modelos que incorporen autocorrelación espacial (como modelos SAR o CAR) o adoptar enfoques de regresión geográficamente ponderada o modelos jerárquicos bayesianos.</p>
<section id="ejemplo-con-statsmodels">
<h3>Ejemplo con Statsmodels<a class="headerlink" href="#ejemplo-con-statsmodels" title="Permalink to this heading">#</a></h3>
<p>Simulamos una variable binaria y como respuesta a dos covariables x1 (continua) y x2 (binaria).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">500</span>

<span class="c1"># Covariables</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="c1"># Coeficientes verdaderos</span>
<span class="n">beta_0</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span>
<span class="n">beta_1</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">beta_2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>

<span class="c1"># Probabilidad con función logística</span>
<span class="n">lin_pred</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">beta_2</span> <span class="o">*</span> <span class="n">x2</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lin_pred</span><span class="p">))</span>

<span class="c1"># Variable respuesta binaria</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x1&#39;</span><span class="p">:</span> <span class="n">x1</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">:</span> <span class="n">x2</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Agregar constante</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]])</span>  <span class="c1"># añade la constante (intercepto)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="c1"># Ajuste del modelo</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.456092
         Iterations 6
                           Logit Regression Results                           
==============================================================================
Dep. Variable:                      y   No. Observations:                  500
Model:                          Logit   Df Residuals:                      497
Method:                           MLE   Df Model:                            2
Date:                Sat, 14 Jun 2025   Pseudo R-squ.:                  0.2995
Time:                        14:58:06   Log-Likelihood:                -228.05
converged:                       True   LL-Null:                       -325.54
Covariance Type:            nonrobust   LLR p-value:                 4.555e-43
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.2504      0.153     -1.638      0.101      -0.550       0.049
x1             1.6643      0.164     10.154      0.000       1.343       1.986
x2            -1.2812      0.242     -5.285      0.000      -1.756      -0.806
==============================================================================
</pre></div>
</div>
</div>
</div>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Elemento</p></th>
<th class="head"><p>Interpretación</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Dep.</span> <span class="pre">Variable</span></code></p></td>
<td><p>Variable dependiente modelada (respuesta binaria, por ejemplo, <code class="docutils literal notranslate"><span class="pre">y</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">No.</span> <span class="pre">Observations</span></code></p></td>
<td><p>Número total de observaciones utilizadas para ajustar el modelo.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Model</span></code></p></td>
<td><p>Tipo de modelo ajustado, en este caso <code class="docutils literal notranslate"><span class="pre">Logit</span></code>, que indica una regresión logística.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Method</span></code></p></td>
<td><p>Método de estimación utilizado, típicamente <code class="docutils literal notranslate"><span class="pre">MLE</span></code> (Máxima Verosimilitud).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Df</span> <span class="pre">Residuals</span></code></p></td>
<td><p>Grados de libertad residuales: número de observaciones menos el número de parámetros estimados.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Df</span> <span class="pre">Model</span></code></p></td>
<td><p>Grados de libertad del modelo: número de predictores (sin incluir la constante).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">Pseudo</span> <span class="pre">R-squ.</span></code></p></td>
<td><p>Pseudo-R², una medida del poder explicativo del modelo. No debe interpretarse como un R² clásico, pero valores más altos indican mejor ajuste relativo.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">Log-Likelihood</span></code></p></td>
<td><p>Logaritmo de la verosimilitud del modelo ajustado; más cercano a cero es mejor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">LL-Null</span></code></p></td>
<td><p>Log-verosimilitud del modelo nulo (modelo sin predictores, solo constante).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">LLR</span> <span class="pre">p-value</span></code></p></td>
<td><p>Valor p del test de razón de verosimilitud. Evalúa si el modelo completo mejora significativamente con respecto al modelo nulo. Un valor pequeño (p &lt; 0.05) indica que el modelo es estadísticamente significativo.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">converged</span></code></p></td>
<td><p>Indica si el proceso de optimización numérica del modelo ha convergido correctamente.</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p>La siguiente tabla presenta los parámetros estimados para el modelo logístico:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Columna</p></th>
<th class="head"><p>Interpretación</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">coef</span></code></p></td>
<td><p>Estimación del coeficiente <span class="math notranslate nohighlight">\(( \beta_j )\)</span>. Representa el cambio en el <strong>logit</strong> (logaritmo del odds) de la variable respuesta por cada unidad de cambio en la covariable correspondiente.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">err</span></code></p></td>
<td><p>Error estándar de la estimación del coeficiente. Se usa para construir intervalos de confianza y calcular el estadístico z.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">z</span></code></p></td>
<td><p>Estadístico z, calculado como <span class="math notranslate nohighlight">\(( \beta_j / \text{SE} )\)</span>. Sirve para evaluar la significancia del coeficiente bajo la hipótesis nula <span class="math notranslate nohighlight">\(( H_0: \beta_j = 0 )\)</span>.</p></td>
</tr>
<tr class="row-odd"><td><p>`P&gt;</p></td>
<td><p>z</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">[0.025</span>&#160; <span class="pre">0.975]</span></code></p></td>
<td><p>Intervalo de confianza del 95% para el coeficiente <span class="math notranslate nohighlight">\(( \beta_j )\)</span>. Si el intervalo no contiene cero, se considera que el coeficiente es estadísticamente significativo.</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<ul class="simple">
<li><p>Si <span class="math notranslate nohighlight">\(( \beta_j &gt; 0 )\)</span>: A mayor valor de la covariable <span class="math notranslate nohighlight">\(( x_j )\)</span>, aumenta el <strong>log-odds</strong> de que la variable dependiente sea 1.</p></li>
<li><p>Si <span class="math notranslate nohighlight">\(( \beta_j &lt; 0 )\)</span>: A mayor valor de <span class="math notranslate nohighlight">\(( x_j )\)</span>, disminuye el log-odds de éxito.</p></li>
<li><p>Para obtener el <strong>odds ratio</strong>, se aplica: <span class="math notranslate nohighlight">\([\text{OR}_j = \exp(\beta_j)]\)</span><br />
Este valor representa cuánto se multiplica el odds por cada unidad adicional de <span class="math notranslate nohighlight">\(( x_j )\)</span>, manteniendo constante el resto de covariables.</p></li>
</ul>
<hr class="docutils" />
<p>x1 = 2.0542: Por cada unidad adicional en x1, el log-odds de que 𝑦=1 aumenta en 2.05. Es decir, el odds se multiplica por exp(2.0542)≈7.8.</p>
<p>x2 = -1.0762: Si x2 pasa de 0 a 1 (es binaria), el log-odds de éxito disminuye en 1.08. El odds se reduce por un factor de exp⁡(−1.0762)≈0.34.</p>
<p>El valor LLR p-value: 3.591e-60 indica que el modelo con predictores explica significativamente más que el modelo nulo. Esto es evidencia a favor del modelo propuesto.</p>
</section>
<section id="ejemplo-con-sklearn">
<h3>Ejemplo con Sklearn<a class="headerlink" href="#ejemplo-con-sklearn" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
</pre></div>
</div>
</div>
</div>
<p>Simulamos dos covariables 𝑥1 y 𝑥2, y una respuesta binaria 𝑦 con base en un modelo logístico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Variables predictoras</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># Coeficientes reales</span>
<span class="n">beta_0</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">beta_1</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">beta_2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.5</span>

<span class="c1"># Lineal predictor</span>
<span class="n">eta</span> <span class="o">=</span> <span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">beta_2</span> <span class="o">*</span> <span class="n">x2</span>

<span class="c1"># Probabilidad con función logística</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">eta</span><span class="p">))</span>

<span class="c1"># Variable binaria (respuesta)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># Crear DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x1&#39;</span><span class="p">:</span> <span class="n">x1</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">:</span> <span class="n">x2</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelo logístico</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">])</span>

<span class="c1"># Coeficientes estimados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercepto:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coeficientes:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercepto: [-1.2763089]
Coeficientes: [[ 2.19119924 -1.47935977]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]])</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]])[:,</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#probabilidad del si</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matriz de confusión</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matriz de confusión:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Métricas</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de clasificación:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># AUC y curva ROC</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">y_prob</span><span class="p">)</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">y_prob</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Falso positivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Verdadero positivo&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matriz de confusión:
[[866  17]
 [ 53  64]]

Reporte de clasificación:
              precision    recall  f1-score   support

           0       0.94      0.98      0.96       883
           1       0.79      0.55      0.65       117

    accuracy                           0.93      1000
   macro avg       0.87      0.76      0.80      1000
weighted avg       0.92      0.93      0.92      1000
</pre></div>
</div>
<img alt="_images/f09c1547c22192c50ca498e28ceef063157ae8eda4180e13d35700dc6b9e161c.png" src="_images/f09c1547c22192c50ca498e28ceef063157ae8eda4180e13d35700dc6b9e161c.png" />
</div>
</div>
</section>
</section>
<section id="modelo-de-poisson">
<h2>Modelo de Poisson<a class="headerlink" href="#modelo-de-poisson" title="Permalink to this heading">#</a></h2>
<p>La distribución de Poisson se utiliza debido a su adecuación para modelar datos de conteo no negativos (<span class="math notranslate nohighlight">\(𝑌_𝑖\)</span>=0,1,2,…) y su relación con procesos que cuentan la ocurrencia de eventos en el espacio. La distribución de Poisson describe la probabilidad de que un número de eventos <span class="math notranslate nohighlight">\(𝑌_𝑖\)</span> ocurra en un intervalo de tiempo o una región espacial dada, si esos eventos suceden con una tasa constante <span class="math notranslate nohighlight">\(𝜆_𝑖\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(Y_i = y_i) = \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!}, \quad y_i = 0, 1, 2, \ldots
\]</div>
<p>donde: <span class="math notranslate nohighlight">\(𝜆_𝑖\)</span>: tasa o intensidad esperada del número de eventos en la región, <span class="math notranslate nohighlight">\(𝑖\)</span>, <span class="math notranslate nohighlight">\(𝑦_𝑖\)</span>: número observado de eventos en la región <span class="math notranslate nohighlight">\(𝑖\)</span>.</p>
<p>Los Modelos Lineales Generalizados (GLM) son modelos en los que las variables de respuesta siguen una distribución distinta a la distribución normal. El modelo lineal generalizado de Poisson se especifica de la siguiente manera:</p>
<div class="math notranslate nohighlight">
\[
\lambda_i = \mathbb{E}[Y_i] = e^{\eta_i}
\]</div>
<p>donde:</p>
<div class="math notranslate nohighlight">
\[
\eta_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}
\]</div>
<p>y <span class="math notranslate nohighlight">\(𝜂_𝑖\)</span> es la parte lineal del modelo que depende de las covariables <span class="math notranslate nohighlight">\(𝑥_{𝑖j}\)</span> y de los parámetros <span class="math notranslate nohighlight">\(𝛽_𝑗\)</span> (para <span class="math notranslate nohighlight">\(𝑗=0,1,…,𝑝\)</span>. En los modelos de Regresión de Poisson, las variables predictoras o explicativas pueden ser una mezcla de valores numéricos o categóricos.</p>
<p>En el modelo de Poisson, la función de enlace que relaciona la media <span class="math notranslate nohighlight">\(𝜆_𝑖\)</span> con la parte lineal <span class="math notranslate nohighlight">\(𝜂_𝑖\)</span> es el logaritmo natural. Es decir, la función de enlace es:</p>
<div class="math notranslate nohighlight">
\[
\eta_i = \log(\lambda_i)
\]</div>
<p>De esta forma, la media de la distribución de Poisson se relaciona exponencialmente con la combinación lineal de las covariables:</p>
<div class="math notranslate nohighlight">
\[
\lambda_i = e^{\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}
\]</div>
<p>Esta forma asegura que la intensidad <span class="math notranslate nohighlight">\(𝜆_𝑖\)</span> siempre será positiva, como es necesario en una distribución de Poisson.</p>
<p>Los coeficientes se calculan utilizando métodos como la Estimación de Máxima Verosimilitud (MLE) o la cuasi-verosimilitud máxima.</p>
<p>La distribución de Poisson puede ser considerada como el límite de una distribución binomial. La distribución binomial modela el número de éxitos en un número fijo de ensayos independientes. Si el número de ensayos es muy grande, pero la probabilidad de éxito en cada ensayo es muy baja (es decir, si los eventos son raros), la distribución de Poisson resulta ser una muy buena aproximación para modelar el número total de éxitos. Mientras que la distribución de Poisson se usa, entonces, para modelar situaciones en las que estamos contando eventos raros que ocurren a lo largo de un intervalo (de tiempo, espacio, etc.). Por ejemplo, la cantidad de accidentes de tráfico en un cruce por día, o el número de llamadas que llegan a un centro de emergencias por minuto.</p>
<p>En el contexto de un modelo de Poisson, como los Modelos Lineales Generalizados de Poisson (GLM de Poisson) para análisis espacial, los términos <strong>sobredispersión</strong> y <strong>subdispersión</strong> se refieren a la relación entre la varianza y la media de los datos observados, y cómo esta relación se ajusta a las expectativas de la distribución de Poisson. Estos conceptos son cruciales porque la distribución de Poisson tiene una característica específica: la media y la varianza son iguales. Sin embargo, en la práctica, los datos espaciales frecuentemente presentan patrones que difieren de esta suposición, lo que da lugar a la sobredispersión o la subdispersión.</p>
<p>En un modelo de Poisson, la media y la varianza están directamente relacionadas de la siguiente manera:</p>
<p>Si <span class="math notranslate nohighlight">\(𝑌_𝑖\)</span> sigue una distribución de Poisson con media <span class="math notranslate nohighlight">\(𝜆_𝑖\)</span>:</p>
<div class="math notranslate nohighlight">
\[
Var(𝑌_𝑖)=𝐸[𝑌_𝑖]=𝜆_𝑖​
\]</div>
<p>Es decir, la varianza y la media son iguales. Esta propiedad, sin embargo, no siempre se cumple cuando se modelan datos reales, especialmente en datos espaciales.</p>
<p>La sobredispersión ocurre cuando la varianza de los datos es mayor que la media. Es decir, los datos muestran más variabilidad de la que el modelo de Poisson predice. La sobredispersión indica que el modelo subestima la variabilidad en los datos. Puede ser causada por factores no observados que afectan el proceso, creando clústeres o patrones espaciales. Por ejemplo, si se modela el número de deslizamientos en una región, pero existen factores locales que varían significativamente dentro de la región (como el tipo de suelo o las prácticas de manejo del terreno), la variabilidad observada en los deslizamientos será mayor que la predicha por la simple distribución de Poisson.
Los modelos de Poisson no pueden manejar adecuadamente este tipo de situación porque asumen una relación 1:1 entre la media y la varianza. Cuando hay sobredispersión, el modelo suele producir errores estándar subestimados, lo que puede llevar a test estadísticos incorrectos y a la identificación de relaciones significativas falsas. Una opción común para manejar la sobredispersión es utilizar un modelo de binomial negativo. Este modelo introduce un parámetro adicional que permite ajustar la varianza de manera independiente de la media.</p>
<p>La subdispersión ocurre cuando la varianza de los datos es menor que la media. En este caso, los datos presentan menos variabilidad de la que la distribución de Poisson predice. La subdispersión es menos común que la sobredispersión en la práctica, pero puede ocurrir en ciertos contextos donde los eventos están altamente regulados o tienen un patrón regular.
Un ejemplo podría ser el número de árboles plantados siguiendo un esquema regular en una región o una situación en la que la influencia espacial está restringida, causando que los eventos ocurran de manera muy controlada y menos variable. Manejar la subdispersión es menos común, pero se puede utilizar una reformulación del modelo que considere una menor variabilidad. Esto implica ajustar la especificación del modelo, por ejemplo, restringiendo el rango de valores posibles para las observaciones. También se podrían utilizar modelos como la regresión cuasi-Poisson, donde se ajusta la varianza independientemente de la media para modelar la subdispersión.</p>
<p>El proceso de puntos de Poisson a veces se llama proceso puramente o completamente aleatorio. Este proceso tiene la propiedad de que el número de eventos <span class="math notranslate nohighlight">\(N(A)\)</span> en una región acotada <span class="math notranslate nohighlight">\(A \in \mathbb{R}^d\)</span> está distribuido de manera independiente y uniforme sobre <span class="math notranslate nohighlight">\(A\)</span>. Esto significa que la ubicación de un punto no afecta las probabilidades de que otros puntos aparezcan cerca y que no hay regiones donde los eventos sean más propensos a aparecer.</p>
<p>Si un proceso de puntos de Poisson tiene un parámetro constante, digamos, <span class="math notranslate nohighlight">\(\lambda\)</span>, entonces se llama proceso de <strong>Poisson homogéneo (o estacionario) (HPP)</strong>. El parámetro <span class="math notranslate nohighlight">\(\lambda\)</span>, llamado intensidad, está relacionado con el número esperado (o promedio) de puntos de Poisson que existen en alguna región acotada. El parámetro <span class="math notranslate nohighlight">\(\lambda\)</span> se puede interpretar como el número promedio de puntos por alguna unidad de longitud, área o volumen, dependiendo del espacio matemático subyacente, por lo que a veces se llama densidad media.</p>
<p>El HPP es estacionario y los patrones y procesos de puntos espaciales son isotrópicos. Es estacionario porque la intensidad es constante y, además, es isotrópico porque la intensidad es invariante a la rotación de <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>.</p>
<p>Una generalización del HPP que permite una intensidad no constante <span class="math notranslate nohighlight">\(\lambda\)</span> se llama proceso de <strong>Poisson no-homogéneo (IPP)</strong>. Tanto el HPP como el IPP asumen que los eventos ocurren de manera independiente y están distribuidos según una intensidad dada, <span class="math notranslate nohighlight">\(\lambda\)</span>. La principal diferencia es que el HPP asume que la función de intensidad es constante (<span class="math notranslate nohighlight">\(\lambda = \text{const.}\)</span>), mientras que la intensidad de un IPP varía espacialmente (<span class="math notranslate nohighlight">\(\lambda = Z(u)\)</span>).</p>
<p>En el plano <span class="math notranslate nohighlight">\((\mathbb{R}^2)\)</span>, el proceso de puntos de Poisson se conoce como <strong>proceso de Poisson espacial</strong>. En una región acotada <span class="math notranslate nohighlight">\(A\)</span> en un plano <span class="math notranslate nohighlight">\((\mathbb{R}^2)\)</span>, con <span class="math notranslate nohighlight">\(N(A)\)</span> siendo el número (aleatorio) de puntos <span class="math notranslate nohighlight">\(N\)</span> que existen en la región <span class="math notranslate nohighlight">\(A \subset \mathbb{R}^2\)</span>, un proceso de Poisson homogéneo con parámetro <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> describe la probabilidad de que existan <span class="math notranslate nohighlight">\(n\)</span> puntos en <span class="math notranslate nohighlight">\(A\)</span> mediante:</p>
<p><span class="math notranslate nohighlight">\( 
P\{N(A) = n\} = \frac{\lambda^{|A|} (|A|)^n}{n!} e^{-\lambda |A|} 
\)</span></p>
<p>donde <span class="math notranslate nohighlight">\(|A|\)</span> denota el área de <span class="math notranslate nohighlight">\(A\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">poisson</span>

<span class="c1"># Define the parameter (lambda, or average rate of occurrence)</span>
<span class="n">lambda_rate</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># Average number of events in an interval</span>

<span class="c1"># Generate a range of values (k) for which we will calculate the probability</span>
<span class="n">k_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>  <span class="c1"># Values of k (number of events)</span>

<span class="c1"># Calculate the probability mass function (PMF) for each k</span>
<span class="n">pmf_values</span> <span class="o">=</span> <span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k_values</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">lambda_rate</span><span class="p">)</span>

<span class="c1"># Plot the Poisson distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">k_values</span><span class="p">,</span> <span class="n">pmf_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Poisson Distribution (lambda = </span><span class="si">{</span><span class="n">lambda_rate</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of events (k)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/972a97aeee0e60c668407cec4071188e740ee7c4d45dfed634f9aa9e0e0d9a28.png" src="_images/972a97aeee0e60c668407cec4071188e740ee7c4d45dfed634f9aa9e0e0d9a28.png" />
</div>
</div>
<section id="ejemplo-1-de-un-glm-de-poisson-homogeneo">
<h3>Ejemplo 1 de un GLM de Poisson homogéneo<a class="headerlink" href="#ejemplo-1-de-un-glm-de-poisson-homogeneo" title="Permalink to this heading">#</a></h3>
<p>Supongamos que estamos analizando la cantidad de “puntos calientes” de incendios forestales en diferentes celdas de una cuadrícula en una región forestal. Queremos modelar cómo ciertos factores ambientales afectan el número de puntos calientes en cada celda. Los factores considerados son la temperatura media de la celda, la humedad relativa y la densidad de vegetación (medida con el índice NDVI). Utilizaremos un modelo de Poisson para modelar el número de puntos calientes en función de estas covariables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Librerías necesarias</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1"># Crear un conjunto de datos simulado con pandas</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;temperatura&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>  <span class="c1"># Temperatura media en grados Celsius</span>
    <span class="s1">&#39;humedad_relativa&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>  <span class="c1"># Humedad relativa en porcentaje</span>
    <span class="s1">&#39;ndvi&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>  <span class="c1"># NDVI (densión de vegetación, entre 0 y 1)</span>
    <span class="s1">&#39;puntos_calientes&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># Número de puntos calientes detectados</span>
<span class="p">}</span>

<span class="c1"># Convertir los datos en un DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Describir los primeros datos del DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   temperatura  humedad_relativa      ndvi  puntos_calientes
0    32.865639         23.014581  0.572018                 2
1    21.070668         22.094693  0.401562                 4
2    28.201852         53.069598  0.544974                 2
3    31.505537         46.290717  0.409959                 1
4    30.919173         70.350824  0.617257                 3
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ajustar un modelo GLM de Poisson utilizando statsmodels</span>
<span class="c1"># La fórmula describe el modelo: puntos_calientes ~ temperatura + humedad_relativa + ndvi</span>
<span class="n">modelo_poisson</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;puntos_calientes ~ temperatura + humedad_relativa + ndvi&quot;</span><span class="p">,</span> 
                         <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> 
                         <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Poisson</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Resumen del modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="n">modelo_poisson</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:       puntos_calientes   No. Observations:                  100
Model:                            GLM   Df Residuals:                       96
Model Family:                 Poisson   Df Model:                            3
Link Function:                    Log   Scale:                          1.0000
Method:                          IRLS   Log-Likelihood:                -184.92
Date:                Sat, 14 Jun 2025   Deviance:                       97.186
Time:                        14:58:09   Pearson chi2:                     85.2
No. Iterations:                     4   Pseudo R-squ. (CS):            0.03179
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept            1.5558      0.429      3.623      0.000       0.714       2.397
temperatura         -0.0024      0.011     -0.223      0.823      -0.024       0.019
humedad_relativa    -0.0047      0.003     -1.426      0.154      -0.011       0.002
ndvi                -0.3842      0.312     -1.232      0.218      -0.995       0.227
====================================================================================
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El coeficiente para “temperatura” indica el cambio en la tasa esperada de puntos calientes por unidad adicional de temperatura.</p></li>
<li><p>El coeficiente para “humedad_relativa” indica cómo afecta la humedad relativa a la tasa de ocurrencia de puntos calientes. Si el coeficiente es negativo, una mayor humedad podría reducir la probabilidad de que ocurran puntos calientes.</p></li>
<li><p>El coeficiente para “ndvi” describe el impacto de la densidad de vegetación sobre el número de puntos calientes.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gráfico simple de puntos calientes vs temperatura para ilustrar la correlación</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;temperatura&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;puntos_calientes&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Temperatura Media (Celsius)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Número de Puntos Calientes&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Puntos Calientes vs Temperatura&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/874dc2d6e04f9101b6dd1c5f18835e4591ec3107e15d926a7a04b628aab61cfc.png" src="_images/874dc2d6e04f9101b6dd1c5f18835e4591ec3107e15d926a7a04b628aab61cfc.png" />
</div>
</div>
<p>Si los coeficientes de “temperatura” y “ndvi” son positivos, esto sugiere que a mayor temperatura y mayor densidad de vegetación, se incrementa la probabilidad de tener más puntos calientes. Si el coeficiente de “humedad_relativa” es negativo, indica que un incremento en la humedad relativa reduce el número esperado de puntos calientes.</p>
</section>
<section id="ejemplo-2-de-un-glm-de-poisson-homogeneo">
<h3>Ejemplo 2 de un GLM de Poisson homogéneo<a class="headerlink" href="#ejemplo-2-de-un-glm-de-poisson-homogeneo" title="Permalink to this heading">#</a></h3>
<p>Cualquier modelo estadístico que describa datos que ocurren en puntos localizados en el tiempo, como los tiempos de disparo de neuronas, se denomina modelo de proceso puntual temporal. Aquí, queremos construir un modelo estadístico que describa la distribución de probabilidad de los tiempos de espera entre los disparos para una neurona sin un estímulo de conducción explícito, en este caso, el modelo debería caracterizar cómo la distribución de los datos depende de las covariables de interés: la posición del ratón y la dirección del movimiento.</p>
<p>Un enfoque utilizado para modelar datos enteros positivos es un modelo de Poisson, en el que usamos un parámetro de tasa, <span class="math notranslate nohighlight">\(\lambda\)</span>, para definir la tasa esperada de disparos en cualquier intervalo de tiempo. Para los datos de interés aquí, ampliamos este concepto definiendo una tasa que varía en el tiempo como una función de un conjunto de covariables. Estas covariables son cualquier variable cuya influencia sobre la actividad de disparo deseemos explorar. Nuestras visualizaciones sugieren que las covariables útiles para nuestro modelo incluyen la posición del ratón y su dirección de movimiento.</p>
<p>Definamos algunos términos. Dejemos que <span class="math notranslate nohighlight">\(X(t)\)</span> represente la posición del ratón en el tiempo <span class="math notranslate nohighlight">\(t\)</span>, y que <span class="math notranslate nohighlight">\(D(t)\)</span> represente la dirección del movimiento; establecemos <span class="math notranslate nohighlight">\(D(t) = -1\)</span> cuando <span class="math notranslate nohighlight">\(X(t)\)</span> está disminuyendo o el ratón está detenido, y <span class="math notranslate nohighlight">\(D(t) = +1\)</span> cuando <span class="math notranslate nohighlight">\(X(t)\)</span> está aumentando. Dado que estas señales de posición y dirección cambian en función del tiempo, también lo hace la tasa de disparo. Escribimos <span class="math notranslate nohighlight">\(\lambda(t) = f(X(t), D(t))\)</span>, donde <span class="math notranslate nohighlight">\(\lambda(t)\)</span> se llama la función de tasa de Poisson, y <span class="math notranslate nohighlight">\(f\)</span> es una función que necesitamos para definir el modelo.</p>
<p>¿Qué función deberíamos usar para <span class="math notranslate nohighlight">\(f(X(t), D(t))\)</span>? Queremos algo que capture la relación entre las covariables y los disparos, y que sea fácil de interpretar. El proceso de encontrar un modelo o conjunto de modelos que sean más consistentes con los datos se llama identificación de modelos o selección de modelos. Típicamente, este es un proceso iterativo en el que proponemos una clase de modelos, encontramos el modelo particular en esa clase que mejor se ajusta a los datos, evaluamos la calidad de ese modelo y decidimos si refinar el modelo aún más o sacar conclusiones del ajuste del modelo. En la práctica, es una buena idea comenzar con estadísticas descriptivas y visualizaciones de la relación entre las covariables y los datos de disparo para seleccionar una clase de modelos de proceso puntual. Para los datos de tren de disparo de interés aquí, nuestras visualizaciones sugieren un modelo donde la dependencia del disparo en la posición tiene una forma de montículo (como en el histograma normalizado por ocupación) e incorpora la dirección. Comenzamos con un modelo demasiado simple para fines pedagógicos.</p>
<p>El siguiente es un modelo muy básico inspirado en la regresión lineal simple:</p>
<div class="math notranslate nohighlight">
\[
\lambda(t) = \beta_0 + \beta_1 X(t)
\]</div>
<p>La idea de la regresión lineal es expresar una variable de respuesta en el tiempo <span class="math notranslate nohighlight">\(t\)</span> en términos de variables predictoras, o covariables. Aquí, <span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span> son parámetros desconocidos utilizados para caracterizar una dependencia lineal entre la variable de respuesta <span class="math notranslate nohighlight">\(\lambda(t)\)</span> y la covariable <span class="math notranslate nohighlight">\(X(t)\)</span>. <span class="math notranslate nohighlight">\(\beta_0\)</span> representa la tasa de disparo esperada en <span class="math notranslate nohighlight">\(X(t) = 0\)</span>, y <span class="math notranslate nohighlight">\(\beta_1\)</span> representa el cambio en la tasa de disparo por cada unidad de aumento en la posición. Este modelo inicial no incluye ninguna dependencia en la dirección de movimiento del ratón (es decir, no hay término <span class="math notranslate nohighlight">\(D(t)\)</span>).</p>
<p>La forma del modelo se parece a una regresión lineal estándar, lo cual es reconfortante porque existen métodos en Python para resolver este tipo de problemas. Sin embargo, los datos observados son eventos de disparo; en tiempo discreto, los datos son conteos de disparos. Una regresión lineal estándar asume que la distribución de los datos, dadas las covariables, es normal. Los conteos de disparos solo pueden tomar valores enteros no negativos, por lo que su distribución no puede ser normal. Cuando el número de conteos de disparos en cada intervalo de tiempo es muy grande, es posible que la distribución de los datos pueda aproximarse por una distribución normal, y en este caso, los métodos de regresión simple podrían funcionar. Pero para los datos de disparo de interés aquí, tenemos muy pocos disparos (0 o 1) en cada intervalo de tiempo de 1 ms, por lo que un ajuste de regresión simple no sería correcto.</p>
<p>En su lugar, debemos ajustar un modelo de regresión de Poisson a los datos. Si dejamos que <span class="math notranslate nohighlight">\(Y_i\)</span> sea el número de disparos observados en el intervalo <span class="math notranslate nohighlight">\(i\)</span>, entonces bajo el modelo de regresión de Poisson, <span class="math notranslate nohighlight">\(Y_i\)</span> tiene una distribución de Poisson con un parámetro de media igual a la variable de respuesta <span class="math notranslate nohighlight">\(\lambda(t)\)</span> integrada sobre el intervalo <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>¿Cómo ajustamos el modelo de regresión de Poisson? Resulta que los modelos de regresión de Poisson de cierta forma se pueden ajustar de manera eficiente utilizando la teoría de modelos lineales generalizados (GLM). En Python, podemos ajustar este modelo utilizando el paquete <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. Antes de aplicar esta función directamente a los datos, obtengamos una visión general de las entradas y salidas de la función. En Python, consideramos el modelo GLM del paquete <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. Construiremos un modelo usando:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">GLM</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X_1</span><span class="p">,</span> <span class="n">family</span><span class="p">(</span><span class="n">link</span><span class="p">()))</span>
</pre></div>
</div>
<p>La primera entrada, <span class="math notranslate nohighlight">\(Y\)</span>, es un vector de los conteos de disparos en cada paso de tiempo. En este caso, <span class="math notranslate nohighlight">\(Y\)</span> es el vector <code class="docutils literal notranslate"><span class="pre">spiketrain</span></code> que calculamos anteriormente. La segunda entrada, <span class="math notranslate nohighlight">\(X_1\)</span>, es una matriz de las covariables de las que depende el disparo. El tamaño de esta matriz es <span class="math notranslate nohighlight">\(n \times p\)</span>, donde <span class="math notranslate nohighlight">\(p\)</span> es el número de covariables en el modelo, y <span class="math notranslate nohighlight">\(n\)</span> es el número de observaciones. Dado que nuestro modelo está dado por <span class="math notranslate nohighlight">\(\lambda(t) = \beta_0 + \beta_1 X(t)\)</span>, añadiremos una columna de unos a la matriz de datos <span class="math notranslate nohighlight">\(X\)</span>, para que podamos ajustar la intersección <span class="math notranslate nohighlight">\(\beta_0\)</span> a nuestros datos. Por lo tanto, <span class="math notranslate nohighlight">\(X_1\)</span> es una matriz <span class="math notranslate nohighlight">\(n \times 2\)</span>, donde <span class="math notranslate nohighlight">\(n\)</span> es el número de puntos de datos (177,761) que representan la posición del ratón a lo largo de la pista. La tercera entrada indica la distribución de los datos de conteo de disparos en <span class="math notranslate nohighlight">\(Y\)</span>. Para un modelo de regresión de Poisson de datos de conteo de disparos, utilizamos la familia de Poisson. De hecho, para la mayoría de los modelos de conteo de disparos neuronales ajustados utilizando GLM, incluso aquellos que no son procesos de Poisson, utilizamos la distribución de Poisson. La entrada <code class="docutils literal notranslate"><span class="pre">family</span></code> se caracteriza por una función de enlace entre la tasa de disparo y las covariables. Específicamente, si queremos ajustar un modelo de la forma <span class="math notranslate nohighlight">\(\lambda(t) = \exp(\beta_0 + \beta_1 X(t))\)</span>, entonces diríamos que la función <span class="math notranslate nohighlight">\(\log(\lambda(t)) = \beta_0 + \beta_1 X(t)\)</span> es la función de enlace. Para el Modelo 1, esta es simplemente la función identidad. A continuación, mostramos una mejor manera de seleccionar esta función de enlace.</p>
<p>El atributo <code class="docutils literal notranslate"><span class="pre">params</span></code> de la función <code class="docutils literal notranslate"><span class="pre">fit</span></code> es un vector de números que representa las estimaciones de máxima verosimilitud de los parámetros del modelo, que para este ejemplo hemos etiquetado como <span class="math notranslate nohighlight">\(\beta_0\)</span> y <span class="math notranslate nohighlight">\(\beta_1\)</span>. Usamos la notación con “sombrero” (hat) sobre un parámetro para representar su estimación. La estimación de máxima verosimilitud de <span class="math notranslate nohighlight">\(\beta_0\)</span> se escribe como <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span>, y la estimación de máxima verosimilitud de <span class="math notranslate nohighlight">\(\beta_1\)</span> se escribe como <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span>. Ahora, usemos esta función para ajustar los parámetros del Modelo 1 a los datos observados de ubicación y disparos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/Mark-Kramer/Case-Studies-Python/raw/master/matfiles/spikes-1.mat&#39;</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">open</span><span class="p">(</span><span class="s1">&#39;spikles-1.mat&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1761663
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">loadmat</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">loadmat</span><span class="p">(</span><span class="s2">&quot;spikles-1.mat&quot;</span><span class="p">)</span>  
<span class="n">t</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;t&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span>              
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">]</span>             
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>                     
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3843ed459d6f20ac0f1426e73854ded5149ef31b2a4ad6f1dd8f049cea642a52.png" src="_images/3843ed459d6f20ac0f1426e73854ded5149ef31b2a4ad6f1dd8f049cea642a52.png" />
</div>
</div>
<p>El gráfico muestra que la rata corre de un lado a otro de manera consistente, realizando aproximadamente 15 pasadas durante los 3 minutos de grabación. También observamos que la rata se mueve bastante rápido en cada pasada, pero pasa una gran cantidad de tiempo en ambos extremos de la pista (cerca de la posición 0 cm o 100 cm) antes de girar y continuar.</p>
<p>A continuación, nos gustaría graficar la actividad de disparo en relación con la trayectoria de movimiento de la rata. Sin embargo, no podemos simplemente graficar el vector X contra el vector spiketimes; estos vectores tienen longitudes diferentes. La longitud de X es la misma que la longitud de t, el número total de intervalos de tiempo de 1 ms en la grabación (177,761 intervalos de tiempo). La longitud de spiketimes es el número total de picos que ocurrieron durante la duración de la grabación: 220 picos. Por lo tanto, el primer paso para visualizar la actividad de disparo específica del lugar es usar spiketimes para crear un nuevo vector, del mismo tamaño que X, que indique si se produjo un pico en cada intervalo de tiempo. Llamaremos a este vector spiketrain, y contendrá un 1 para cada intervalo de tiempo donde ocurre un pico y un 0 para cada intervalo de tiempo que no tiene un pico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spiketimes</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;spiketimes&#39;</span><span class="p">]</span>
<span class="n">n_bins</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="c1"># Histogram spikes into bins centered at times t:</span>
<span class="n">spiketrain</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">spiketimes</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">n_bins</span><span class="p">,</span> <span class="nb">range</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">spikeindex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">spiketrain</span><span class="o">!=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>     <span class="c1"># Get the spike indices.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>                               <span class="c1"># Plot the position,</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">spikeindex</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">spikeindex</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>  <span class="c1"># ... and the spikes.  </span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [sec]&#39;</span><span class="p">)</span>                     <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/70414d9cbc6f65650caaf86e4256a42ec341da35a5f54e92e66e1ef91eae6239.png" src="_images/70414d9cbc6f65650caaf86e4256a42ec341da35a5f54e92e66e1ef91eae6239.png" />
</div>
</div>
<p>A partir de la figura anterior, está claro que la mayor parte de la actividad de picos ocurre cuando la rata está corriendo hacia arriba en la pista, en la dirección donde X está aumentando, en valores de X que van desde unos 50 cm hasta unos 80 cm. No vemos la misma actividad de picos en esta región cuando la rata está corriendo hacia abajo en la pista, en la dirección donde X está disminuyendo. Algunos picos ocurren en otras ubicaciones, pero estos parecen escasos en comparación con el disparo específico de lugar en esta región.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">106</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>                              <span class="c1"># Define spatial bins.</span>
<span class="n">spikehist</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">spikeindex</span><span class="p">],</span> <span class="n">bin_edges</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>           <span class="c1"># Histogram positions @ spikes.</span>
<span class="n">occupancy</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bin_edges</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mf">0.001</span>                 <span class="c1"># Convert occupancy to seconds.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">spikehist</span><span class="o">/</span><span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                                      <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b2b82d2c98f3e38e23e2b95fc662919e6eaf69f52cf7330b9b402b5a5f16a5a0.png" src="_images/b2b82d2c98f3e38e23e2b95fc662919e6eaf69f52cf7330b9b402b5a5f16a5a0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.genmod.families</span> <span class="kn">import</span> <span class="n">Poisson</span>
<span class="kn">from</span> <span class="nn">statsmodels.genmod.families.links</span> <span class="kn">import</span> <span class="n">identity</span>

<span class="c1"># Create a dataframe of predictors that includes X and a constant term</span>
<span class="n">predictors</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Intercept&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>

<span class="c1"># GLM model with Poisson family and identity link function</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">(</span><span class="n">identity</span><span class="p">()))</span>
<span class="n">model1_results</span> <span class="o">=</span> <span class="n">model1</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># Fit model to our data</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">model1_results</span><span class="o">.</span><span class="n">params</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b1:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/evaristizabalg/anaconda3/envs/ml/lib/python3.10/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The identity link alias is deprecated. Use Identity instead. The identity link alias will be removed after the 0.15.0 release.
  warnings.warn(
/home/evaristizabalg/anaconda3/envs/ml/lib/python3.10/site-packages/statsmodels/genmod/generalized_linear_model.py:308: DomainWarning: The identity link function does not respect the domain of the Poisson family.
  warnings.warn((f&quot;The {type(family.link).__name__} link function &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b1:
Intercept   -0.000097
X            0.000027
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Inicialmente, es posible que notes que Python emite una advertencia en la línea de comandos indicando que este modelo—particularmente la función de enlace de identidad—puede ser inapropiado. Ignoraremos esta advertencia e intentaremos interpretar las estimaciones de los parámetros resultantes. El primero de estos valores es la estimación de máxima verosimilitud para <span class="math notranslate nohighlight">\(\beta_0\)</span>. Si creemos que este modelo es preciso, podríamos interpretar este parámetro como indicativo de que la tasa de disparo esperada en la posición <span class="math notranslate nohighlight">\(X(t) = 0\)</span> es de <span class="math notranslate nohighlight">\(-0.097\)</span> picos por milisegundo, o aproximadamente <span class="math notranslate nohighlight">\(-0.097\)</span> picos por segundo, y que a medida que la rata se mueve en la dirección positiva, la tasa de disparo aumenta en <span class="math notranslate nohighlight">\(\beta_1\)</span> picos por segundo por cada centímetro que la rata se mueve.</p>
<p>Este resultado debería levantar algunas señales de advertencia de inmediato. El hecho de que la tasa de disparo sea negativa indica que el modelo se vuelve ininterpretable para los valores observados de <span class="math notranslate nohighlight">\(X(t)\)</span>. Esto sugiere un problema importante con el Modelo 1: la tasa de disparo es negativa, lo que motiva cambios en la función de enlace del modelo. Para visualizar mejor la calidad de este modelo, podemos comparar la dependencia que define entre la posición y la tasa de disparo con el histograma normalizado por ocupación que calculamos anteriormente. En este caso, utilizamos las posiciones definidas por los intervalos del histograma y calculamos la tasa de disparo modelada en estos puntos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">spikehist</span><span class="o">/</span><span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>    <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,(</span><span class="n">b1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">b1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">bins</span><span class="p">)</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>
     <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Model spike rate&quot;</span><span class="p">)</span>             <span class="c1"># Plot model.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                    <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;b1 = [</span><span class="si">{0[0]:.4}</span><span class="s2">, </span><span class="si">{0[1]:.4}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">b1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/27981b044f38b90d2b5989db673836a56584947c3eb10d0c28c8d9c5d2a3a2b2.png" src="_images/27981b044f38b90d2b5989db673836a56584947c3eb10d0c28c8d9c5d2a3a2b2.png" />
</div>
</div>
<p>Vemos que la tasa de disparo del modelo captura algunas características del disparo observado, por ejemplo, el hecho de que la tasa de disparo aumenta a medida que la rata se mueve desde la posición <span class="math notranslate nohighlight">\(x = 0\)</span> hacia la posición <span class="math notranslate nohighlight">\(x = 60\)</span>. Pero el modelo no capta gran parte de la estructura, por ejemplo, el hecho de que la tasa de disparo no cambia linealmente con la posición y comienza a disminuir cuando la posición de la rata supera los <span class="math notranslate nohighlight">\(x = 70\)</span>. Esto sugiere un segundo problema con este modelo: la forma de la relación entre la posición y la tasa de disparo es incorrecta.</p>
<p>Concluimos que nuestra propuesta inicial, el Modelo 1, no representa bien los datos. Por lo tanto, refinemos el modelo para abordar los problemas identificados. Primero, elijamos una función de enlace que sea más apropiada para el modelado de procesos puntuales. Nos gustaría una función que asegure que la función de tasa sea no negativa y que sea fácil de ajustar. La teoría del modelado lineal generalizado sugiere una función en particular: el enlace logarítmico. Establecemos que el logaritmo de la tasa de disparo sea una función lineal de las covariables. Si mantenemos la posición como la única covariable, esto conduce a un modelo de la forma:</p>
<div class="math notranslate nohighlight">
\[
\log(\lambda(t)) = \beta_0 + \beta_1 X(t)
\]</div>
<p>o, de manera equivalente,</p>
<div class="math notranslate nohighlight">
\[
\lambda(t) = \exp(\beta_0 + \beta_1 X(t))
\]</div>
<p>Esta función de enlace se llama el enlace canónico para datos de Poisson. Tiene una serie de propiedades atractivas. Como se deseaba, asegura que la función de tasa sea positiva.</p>
<p><strong>P:</strong> Considera la expresión para <span class="math notranslate nohighlight">\(\lambda(t)\)</span> arriba. ¿Por qué <span class="math notranslate nohighlight">\(\lambda(t)\)</span> debe ser siempre positiva?</p>
<p>La elección de un enlace logarítmico también asegura que la verosimilitud de los datos sea cóncava con respecto a los parámetros del modelo. Esto significa que la verosimilitud solo tiene un valor máximo local, que es la estimación de máxima verosimilitud (ML). También se puede demostrar que, en muchos casos, los estimadores de los parámetros serán asintóticamente normales, lo que nos permitirá construir intervalos de confianza y hacer declaraciones de significancia sobre ellos [Kass, Eden &amp; Brown, 2014].</p>
<p>Para ajustar el Modelo 2 en Python, usamos el mismo modelo que antes pero reemplazamos la función de enlace con <span class="math notranslate nohighlight">\(\log\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span> <span class="c1"># GLM model with Poisson family and log link function</span>
<span class="n">model2_results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># Fit model to our data</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">params</span>    <span class="c1"># Get the predicted coefficient vector</span>
</pre></div>
</div>
</div>
</div>
<p>De hecho, si omitimos el nombre de la función de enlace en la rutina <code class="docutils literal notranslate"><span class="pre">sm.GLM</span></code>, esta usará automáticamente el enlace canónico para la distribución seleccionada. Dado que el enlace logarítmico es canónico para datos de Poisson, simplemente podemos ejecutar los comandos:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">spiketrain</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Poisson</span><span class="p">())</span>  <span class="c1"># GLM model with Poisson family, omitting link function</span>
<span class="n">model2_results</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>  <span class="c1"># Fit model to our data</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">model2_results</span><span class="o">.</span><span class="n">params</span>     <span class="c1"># Get the predicted coefficient vector</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept   -7.438887
X            0.012943
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Esta vez, encontramos que Python no emite una advertencia sobre la posible inapropiedad de la función de enlace. La inspección de los valores estimados de los parámetros revela <span class="math notranslate nohighlight">\(b_2 = [-7.43888719, 0.01294342]\)</span>. Estos valores son marcadamente diferentes de los valores de parámetros <span class="math notranslate nohighlight">\(b_1\)</span> encontrados usando el Modelo 1. La razón de esta diferencia es que la forma del modelo tiene un impacto importante en la interpretación de los valores de los parámetros. A continuación, discutimos la interpretación de estos valores de los parámetros en detalle.</p>
<p>Examinemos el ajuste del modelo más de cerca. Cuando <span class="math notranslate nohighlight">\(x = 0\)</span>, la tasa de disparo bajo el Modelo 2 es:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\lambda(t) &amp;= \exp(\beta_0 + \beta_1 \times 0) \\
           &amp;= \exp(\beta_0) \\
           &amp;= 0.0006\text{ spikes/ms} \\
           &amp;= 0.6 \text{ spikes/s}
\end{align}
\end{split}\]</div>
<p>donde hemos utilizado el valor <span class="math notranslate nohighlight">\(b_2[0]\)</span>. Si el ratón se mueve de la posición <span class="math notranslate nohighlight">\(x = 0\)</span> a <span class="math notranslate nohighlight">\(x = 1\)</span>, la tasa de disparo se convierte en:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}\lambda(t) &amp;= \exp(\beta_0 + \beta_1 × 1) \\
  &amp;= \exp(\beta_0 + \beta_1)\\
  &amp;= \exp(\beta_0)\exp(\beta_1)\\
  &amp;= 1.013 \exp(\beta_0),\end{align}
\end{split}\]</div>
<p>donde hemos utilizado el valor <span class="math notranslate nohighlight">\(b_2[1]\)</span>. Es decir, un aumento de 1 cm en la posición incrementa la tasa de disparo en un 1.3%. Debido a la función de enlace, la posición ahora tiene un efecto multiplicativo en lugar de aditivo sobre la tasa de disparo. En lugar de sumar a la tasa de disparo, cada aumento de posición conduce a una modulación multiplicativa de la tasa de disparo, con un incremento de aproximadamente un 1% por cm. Veamos cómo se ve este modelo comparándolo con el histograma normalizado por ocupación de los datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">spikehist</span><span class="o">/</span><span class="n">occupancy</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>    <span class="c1"># Plot results as bars.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">b2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">bins</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>
     <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model spike rate&#39;</span><span class="p">)</span>             <span class="c1"># Plot model.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position [cm]&#39;</span><span class="p">)</span>                    <span class="c1"># Label the axes.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Occupancy norm. hist. [spikes/s]&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/93d02baa10681e62f5b1a84c5eba3d884b6a4de1230b4a41757489195e2a822c.png" src="_images/93d02baa10681e62f5b1a84c5eba3d884b6a4de1230b4a41757489195e2a822c.png" />
</div>
</div>
<p>La inspección visual sugiere que hemos resuelto un problema: la tasa de disparo ya no es negativa en ningún lugar. Sin embargo, el ajuste del modelo aún no concuerda con la estructura observada en el histograma normalizado por ocupación. Hemos mejorado la función de enlace, pero usar solo la posición como covariable lleva a una tasa que es una función exponencial de la posición del ratón.</p>
<p>Hay muchas variables que podríamos considerar agregar a este modelo, pero ¿qué variables podríamos añadir para capturar mejor la dependencia entre la tasa de disparo y la posición, en particular? Una idea podría ser incluir términos no lineales, como el cuadrado del valor de la posición.</p>
</section>
</section>
<section id="modelo-binomial-negativo">
<h2>Modelo Binomial Negativo<a class="headerlink" href="#modelo-binomial-negativo" title="Permalink to this heading">#</a></h2>
<p>La regresión binomial negativa es un modelo de regresión utilizado para datos de conteo donde la varianza excede la media, un fenómeno conocido como sobredispersión.</p>
<p>Es una extensión de la regresión de Poisson, que relaja el supuesto de igualdad entre media y varianza, permitiendo así un modelado más realista en contextos donde los eventos presentan alta variabilidad.</p>
<p><span class="math notranslate nohighlight">\(yᵢ ~ NegBin(μᵢ, θ)\)</span></p>
<p>donde:</p>
<ul class="simple">
<li><p>𝜇𝑖 es la media esperada para la observación 𝑖</p></li>
<li><p>𝜃 es el parámetro de dispersión</p></li>
</ul>
<p>La función de enlace es:</p>
<p><span class="math notranslate nohighlight">\(log(μᵢ) = β₀ + β₁x₁ᵢ + β₂x₂ᵢ + ... + βₚxₚᵢ\)</span></p>
<p>La varianza bajo la binomial negativa es:</p>
<p><span class="math notranslate nohighlight">\(Var(yᵢ) = μᵢ + μᵢ² / θ\)</span></p>
<p>La dsitribución Binomial y la Binomial negativa se relacionan en ambas derivan de ensayos Bernoulli, el cual es un experimento con dos resultados: éxito (1) o fracaso (0), con probabilidad 𝑝.</p>
<ul class="simple">
<li><p>Distribución binomial: cuenta cuántos éxitos hay en 𝑛 ensayos con probabilidad fija 𝑝.</p></li>
<li><p>Distribución binomial negativa: cuenta cuántos fracasos ocurren antes de alcanzar un número fijo de éxitos 𝑟 (o viceversa, según la parametrización).</p></li>
</ul>
<p>Ambas son distribuciones de conteo discreto y ambas modelan variables aleatorias enteras y no negativas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parámetros del experimento</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span>  <span class="c1"># Probabilidad de éxito (sacar un 6)</span>
<span class="n">r</span> <span class="o">=</span> <span class="mi">5</span>    <span class="c1"># Número de éxitos deseados</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Simular lanzamientos hasta obtener r éxitos</span>
<span class="n">lanzamientos</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">exitos</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">while</span> <span class="n">exitos</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">:</span>
    <span class="n">dado</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    <span class="n">lanzamientos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dado</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dado</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
        <span class="n">exitos</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Convertir a array</span>
<span class="n">lanzamientos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lanzamientos</span><span class="p">)</span>
<span class="n">n_lanzamientos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lanzamientos</span><span class="p">)</span>
<span class="n">fallos</span> <span class="o">=</span> <span class="n">n_lanzamientos</span> <span class="o">-</span> <span class="n">r</span>

<span class="c1"># Visualizar la secuencia</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;green&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">6</span> <span class="k">else</span> <span class="s1">&#39;gray&#39;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">lanzamientos</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_lanzamientos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">n_lanzamientos</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Número de lanzamiento&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lanzamientos hasta obtener </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> éxitos (seis): </span><span class="si">{</span><span class="n">n_lanzamientos</span><span class="si">}</span><span class="s2"> lanzamientos totales, </span><span class="si">{</span><span class="n">fallos</span><span class="si">}</span><span class="s2"> fallos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3cf43e71e7e21787594ae30389c0dbf514d8b32004dd25d6ee0a4e432ae97a12.png" src="_images/3cf43e71e7e21787594ae30389c0dbf514d8b32004dd25d6ee0a4e432ae97a12.png" />
</div>
</div>
<p>Aquí tienes la simulación visual de los lanzamientos de dado:</p>
<ul class="simple">
<li><p>Los puntos verdes representan los éxitos (donde salió un 6).</p></li>
<li><p>Los grises son fallos (cualquier otro número).</p></li>
</ul>
<p>En este experimento, se necesitaron 21 lanzamientos para obtener 5 veces un 6, con 16 fallos intercalados. Esto ilustra perfectamente el concepto de la distribución binomial negativa: modelar cuántos ensayos (o fracasos) se requieren antes de alcanzar un número fijo de éxitos no consecutivos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Repetir el experimento muchas veces</span>
<span class="n">n_repeticiones</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">resultados</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeticiones</span><span class="p">):</span>
    <span class="n">exitos</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">lanzamientos</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">exitos</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">:</span>
        <span class="n">dado</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="n">lanzamientos</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">dado</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
            <span class="n">exitos</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">fallos</span> <span class="o">=</span> <span class="n">lanzamientos</span> <span class="o">-</span> <span class="n">r</span>
    <span class="n">resultados</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fallos</span><span class="p">)</span>

<span class="c1"># Visualizar la distribución de fallos hasta obtener r éxitos</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">resultados</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Distribución de fallos antes de obtener </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> éxitos (Binomial Negativa)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Número de fallos antes de obtener 5 seis&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densidad&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ed67ba6f96557d579dcbe0064190349c8228c317f4e8ad100d71cc7156f2d32e.png" src="_images/ed67ba6f96557d579dcbe0064190349c8228c317f4e8ad100d71cc7156f2d32e.png" />
</div>
</div>
<p>Aquí tienes la distribución empírica del número de fallos antes de obtener 5 éxitos (es decir, 5 veces un 6):</p>
<p>Tiene forma asimétrica (cola larga a la derecha), característica de la binomial negativa.</p>
<p>En promedio, se necesitan más de 20 lanzamientos (fallos + éxitos) para lograrlo, porque el 6 solo tiene una probabilidad de 1/6.</p>
<p>Esto muestra cómo la binomial negativa captura la variabilidad natural en procesos con baja probabilidad de éxito y repeticiones aleatorias.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">nbinom</span>

<span class="c1"># Valores posibles de fallos</span>
<span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">resultados</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Parámetros de la binomial negativa:</span>
<span class="c1"># r = número de éxitos deseados</span>
<span class="c1"># p = probabilidad de éxito por ensayo</span>
<span class="c1"># En scipy, nbinom(k; r, p) da la probabilidad de k fallos antes de r éxitos</span>
<span class="n">pmf_vals</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

<span class="c1"># Gráfico comparativo</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">resultados</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgray&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Simulación&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pmf_vals</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Distribución teórica (NB)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Distribución de fallos antes de </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> éxitos (comparación simulación vs. teórica)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Número de fallos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densidad&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c0e4f58fc3dbdf3001d7dbba20d0a42a02ac08397254f950f4d7c6c62d4bf7c3.png" src="_images/c0e4f58fc3dbdf3001d7dbba20d0a42a02ac08397254f950f4d7c6c62d4bf7c3.png" />
</div>
</div>
<p>Aquí puedes ver la comparación entre la simulación y la distribución teórica binomial negativa:</p>
<p>La histograma gris representa los resultados de nuestras 10,000 simulaciones.</p>
<p>La línea roja es la función de masa de probabilidad (PMF) teórica para la distribución binomial negativa con 𝑟=5, 𝑝=1/6.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Repetir el análisis con distintos valores de p y r fijos (5)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">r</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">max_fallos</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p_val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ps</span><span class="p">):</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_fallos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pmf_vals</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p_val</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pmf_vals</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Binomial Negativa (r=</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2">, p=</span><span class="si">{</span><span class="n">p_val</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Número de fallos antes de 5 éxitos&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densidad&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3b05e72320f31ba11fc7fc2d4612a4ee2a07a199c7535f3b4c8f934b29ebfc0b.png" src="_images/3b05e72320f31ba11fc7fc2d4612a4ee2a07a199c7535f3b4c8f934b29ebfc0b.png" />
</div>
</div>
<p>Aquí puedes ver cómo cambia la forma de la distribución binomial negativa al variar la probabilidad de éxito 𝑝:</p>
<ul class="simple">
<li><p>Cuando 𝑝=0.1 (éxito poco probable), la distribución es más dispersa, con una cola muy larga: se necesitan muchos intentos.</p></li>
</ul>
<p>🔹 Cuando 𝑝=0.3, la distribución se vuelve más concentrada: los 5 éxitos ocurren con menos fallos.</p>
<p>🔹 Cuando 𝑝=0.5, la distribución se vuelve aún más compacta: los éxitos son frecuentes.</p>
<p>Esto muestra cómo la probabilidad de éxito controla la forma y la dispersión de la binomial negativa.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mantener p fijo y variar r (número de éxitos deseados)</span>
<span class="n">p_fixed</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">rs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">max_fallos</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">r_val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rs</span><span class="p">):</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_fallos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pmf_vals</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">r_val</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p_fixed</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pmf_vals</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Binomial Negativa (r=</span><span class="si">{</span><span class="n">r_val</span><span class="si">}</span><span class="s2">, p=</span><span class="si">{</span><span class="n">p_fixed</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Número de fallos antes de </span><span class="si">{r_val}</span><span class="s2"> éxitos&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densidad&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/606ba0a9c9d8b1af775a84974043cd3e883fb63e53655fd92db97c23e590df47.png" src="_images/606ba0a9c9d8b1af775a84974043cd3e883fb63e53655fd92db97c23e590df47.png" />
</div>
</div>
<p>Aquí puedes ver cómo afecta el número de éxitos deseado 𝑟 a la forma de la distribución binomial negativa, manteniendo la probabilidad de éxito fija en
𝑝=0.3:</p>
<p>✅ Cuando 𝑟=2: la distribución es más estrecha y sesgada, porque solo necesitas pocos éxitos → menos variabilidad.</p>
<p>✅ Cuando 𝑟=5: la curva se ensancha y desplaza hacia la derecha.</p>
<p>✅ Cuando 𝑟=10: se vuelve aún más simétrica y extendida: necesitas más éxitos, así que se acumulan más fallos.</p>
<p>En resumen: A mayor 𝑟, más ensayos y mayor dispersión. A menor 𝑝, mayor varianza.</p>
<section id="ejemplo">
<h3>Ejemplo<a class="headerlink" href="#ejemplo" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulación de datos de conteo con sobredispersión</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">pendiente</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">elevacion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">2500</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># Coeficientes del modelo</span>
<span class="n">beta_0</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.0</span>
<span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.04</span>   <span class="c1"># efecto de pendiente</span>
<span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.001</span>  <span class="c1"># efecto de elevación</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mf">1.5</span>     <span class="c1"># parámetro de dispersión (más dispersión)</span>

<span class="c1"># Simular área (por ejemplo, en km²)</span>
<span class="n">area_km2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># áreas entre 1 y 10 km²</span>
<span class="n">log_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">area_km2</span><span class="p">)</span>  <span class="c1"># offset en escala log</span>

<span class="c1"># Media esperada</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">pendiente</span> <span class="o">+</span> <span class="n">beta_2</span> <span class="o">*</span> <span class="n">elevacion</span> <span class="o">+</span> <span class="n">log_area</span><span class="p">)</span>

<span class="c1"># Generar datos de respuesta</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">/</span> <span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">mu</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;pendiente&quot;</span><span class="p">:</span> <span class="n">pendiente</span><span class="p">,</span>
    <span class="s2">&quot;elevacion&quot;</span><span class="p">:</span> <span class="n">elevacion</span><span class="p">,</span>
    <span class="s2">&quot;area_km2&quot;</span> <span class="p">:</span> <span class="n">area_km2</span><span class="p">,</span>
    <span class="s2">&quot;log_area&quot;</span> <span class="p">:</span> <span class="n">log_area</span><span class="p">,</span>
    <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ajustar modelo binomial negativa</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s2">&quot;pendiente&quot;</span><span class="p">,</span> <span class="s2">&quot;elevacion&quot;</span><span class="p">]])</span>
<span class="n">model_nb</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">X</span><span class="p">,</span>
                         <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">NegativeBinomial</span><span class="p">(),</span>
                         <span class="n">offset</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_area&quot;</span><span class="p">])</span>
<span class="n">results_nb</span> <span class="o">=</span> <span class="n">model_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;mu_pred&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;log_area&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/evaristizabalg/anaconda3/envs/ml/lib/python3.10/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.
  warnings.warn(&quot;Negative binomial dispersion parameter alpha not &quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualización en 3D (opcional)</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;pendiente&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;elevacion&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Observado&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;pendiente&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;elevacion&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mu_pred&quot;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicción NB&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Pendiente (°)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Elevación (m)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;Número de eventos&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Regresión binomial negativa con dos covariables&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/231b0e0bd26ee2b1b1a410d38fcfad9491d0295a38a40683a75a9099d8e39db4.png" src="_images/231b0e0bd26ee2b1b1a410d38fcfad9491d0295a38a40683a75a9099d8e39db4.png" />
</div>
</div>
</section>
</section>
<section id="modelo-de-ceros-inflados">
<h2>Modelo de Ceros Inflados<a class="headerlink" href="#modelo-de-ceros-inflados" title="Permalink to this heading">#</a></h2>
<p>Los modelos de conteo clásicos como Poisson o binomial negativa suponen que los ceros ocurren como parte del proceso natural. Pero en muchos contextos reales (como deslizamientos), hay más ceros de los que esos modelos predicen, por ejemplo:</p>
<ul class="simple">
<li><p>Celdas donde realmente no hay condiciones físicas para deslizamientos (ceros estructurales).</p></li>
<li><p>Celdas donde sí podría haber, pero no ocurrieron durante el periodo observado (ceros aleatorios).</p></li>
</ul>
<p>En esos casos, usamos modelos inflados en ceros, que asumen que algunos ceros provienen de un proceso separado.</p>
<p>El modelo ZINB combina:</p>
<ul class="simple">
<li><p>Una parte binaria (modelo logístico) que predice la probabilidad de estar en el grupo “siempre cero”.</p></li>
<li><p>Una parte de conteo (binomial negativa) que modela el número de eventos si no está en el grupo siempre cero.</p></li>
</ul>
<section id="id1">
<h3>Ejemplo<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.discrete.count_model</span> <span class="kn">import</span> <span class="n">ZeroInflatedNegativeBinomialP</span>

<span class="c1"># 1. Simular datos reales</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">tiempo</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># ejemplo: 100 años o meses</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>  <span class="c1"># predictor temporal (puede ser SPI, pendiente promedio, etc.)</span>

<span class="c1"># Modelo real</span>
<span class="n">beta_0</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">beta_0</span> <span class="o">+</span> <span class="n">beta_1</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">nbinom</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">/</span> <span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">mu</span><span class="p">)</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">theta</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">nbinom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># 2. Introducir falsos ceros (subregistro): 25% de los y_true &gt; 0 se vuelven 0</span>
<span class="n">y_obs</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.25</span><span class="p">)</span>
<span class="n">y_obs</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># 3. Preparar datos</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;tiempo&quot;</span><span class="p">:</span> <span class="n">tiempo</span><span class="p">,</span>
    <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
    <span class="s2">&quot;y_obs&quot;</span><span class="p">:</span> <span class="n">y_obs</span><span class="p">,</span>
    <span class="s2">&quot;y_true&quot;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span>
    <span class="s2">&quot;falso_cero&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">y_obs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># 4. Ajustar modelo ZINB (modelo de corrección)</span>
<span class="n">exog</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">])</span>  <span class="c1"># incluye intercepto</span>
<span class="n">zinb_model</span> <span class="o">=</span> <span class="n">ZeroInflatedNegativeBinomialP</span><span class="p">(</span><span class="n">endog</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;y_obs&quot;</span><span class="p">],</span> <span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">exog_infl</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">inflation</span><span class="o">=</span><span class="s2">&quot;logit&quot;</span><span class="p">)</span>
<span class="n">zinb_result</span> <span class="o">=</span> <span class="n">zinb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;bfgs&quot;</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 5. Estimar media esperada corregida</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;mu_pred&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">zinb_result</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span>

<span class="c1"># 6. Visualizar serie original, observada y corregida</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;tiempo&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;y_true&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Valor real (y_true)&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;tiempo&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;y_obs&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Valor observado (con omisión)&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dotted&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;tiempo&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mu_pred&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Valor estimado corregido (ZINB)&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Tiempo&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Número de eventos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Corrección de series con omisión usando modelo ZINB&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8e7c68bd2ad03a309a88d5d3c636d0396364a23e2f0a4743fc25d304a8587413.png" src="_images/8e7c68bd2ad03a309a88d5d3c636d0396364a23e2f0a4743fc25d304a8587413.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="03_PointPattern.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Patrón de puntos</p>
      </div>
    </a>
    <a class="right-next"
       href="06_Coropleta.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Visualización de datos discretos</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-regresion-logistica">Modelo de Regresión Logística</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-con-statsmodels">Ejemplo con Statsmodels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-con-sklearn">Ejemplo con Sklearn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-poisson">Modelo de Poisson</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-1-de-un-glm-de-poisson-homogeneo">Ejemplo 1 de un GLM de Poisson homogéneo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-2-de-un-glm-de-poisson-homogeneo">Ejemplo 2 de un GLM de Poisson homogéneo</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-binomial-negativo">Modelo Binomial Negativo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo">Ejemplo</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-ceros-inflados">Modelo de Ceros Inflados</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Ejemplo</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Edier V. Aristizábal G.
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
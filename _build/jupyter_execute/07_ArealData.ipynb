{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnByUeLrr40t"
   },
   "source": [
    "<p style=\"font-size:11px;\"><em><strong>Créditos</strong>: El contenido de este cuaderno ha sido tomado de varias fuentes, pero especialmente de <a href=\"http://darribas.org/\">Dani Arribas-Bel</a> - University of Liverpool & <a href=\"http://spatial.ucr.edu/peopleRey.html\">Sergio Rey</a> - Center for Geospatial Sciences, University of California, Riverside. El compilador se disculpa por cualquier omisión involuntaria y estaría encantado de agregar un reconocimiento.</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelación espacial\n",
    "\n",
    "La autocorrelación espacial tiene que ver con el grado en que la similitud en los valores entre observaciones en un conjunto de datos está relacionada con la similitud en las ubicaciones de dichas observaciones. No es completamente diferente de la correlación tradicional entre dos variables, que nos informa sobre cómo cambian los valores en una variable en función de los de la otra, y es análoga a su contraparte de series temporales, que relaciona el valor de una variable en un momento dado con los de períodos anteriores. La autocorrelación espacial relaciona el valor de la variable de interés en una ubicación dada con los valores de la misma variable en ubicaciones circundantes.\n",
    "\n",
    "Una idea clave en este contexto es la de aleatoriedad espacial: una situación en la que la ubicación de una observación no proporciona ninguna información sobre su valor. En otras palabras, una variable es espacialmente aleatoria si se distribuye sin seguir un patrón discernible sobre el espacio. Por lo tanto, la autocorrelación espacial puede definirse formalmente como la \"ausencia de aleatoriedad espacial\", lo que da lugar a dos clases principales de autocorrelación, similares al caso tradicional: autocorrelación espacial *positiva*, cuando los valores similares tienden a agruparse en ubicaciones similares; y autocorrelación espacial *negativa*, en casos donde los valores similares tienden a dispersarse y estar más separados entre sí.\n",
    "\n",
    "\n",
    "La herramienta fundamental para evaluar la relación espacial entre observaciones corresponde a la matriz espacial de pesos. La matriz de pesos tiene dimensiones de $N$ by $N$, donde $N$ es el número total de observaciones:\n",
    "\n",
    "$$\n",
    "W = \\left(\\begin{array}{cccc}\n",
    "0 & w_{12} & \\dots & w_{1N} \\\\\n",
    "w_{21} & \\ddots & w_{ij} & \\vdots \\\\\n",
    "\\vdots & w_{ji} & 0 & \\vdots \\\\\n",
    "w_{N1} & \\dots & \\dots & 0 \n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "Donde cada celda $w_{ij}$ corresponde a un valor que representa el grado espacial de contacto o interacción entre los valores $i$ y $j$. Por convención, la diagonal ($w_{ij}$) son ceros. El valor $W$ de $i$ y $j$ son vecinas si $w_{ij}>0$.\n",
    "\n",
    "\n",
    "Una matriz de pesos espaciales es la forma en que el espacio geográfico se codifica formalmente en una forma numérica para que sea fácil de entender para una computadora (o un método estadístico). Ya hemos visto muchas de las formas conceptuales en las que podemos definir una matriz de pesos espaciales, como la contigüidad, basada en la distancia o en bloques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de pesos basada en contiguidad\n",
    "Para este ejemplo, mostraremos cómo construir una matriz de contigüidad **Queen**, que considera dos observaciones como vecinas si comparten al menos un punto de su límite. En otras palabras, para que un par de autoridades locales en el conjunto de datos sean consideradas vecinas bajo este $W$, necesitarán compartir frontera o, en otras palabras, \"tocarse\" en cierto grado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m br \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://darribas.org/gds19/content/labs/data/brexit.gpkg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m br\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "br = gpd.read_file('http://darribas.org/gds19/content/labs/data/brexit.gpkg')\n",
    "br.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = gpd.read_file(br_path).set_index('LAD14CD', drop=False)\n",
    "br.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen = weights.Queen.from_dataframe(br, idVariable=\"LAD14CD\")\n",
    "w_queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la matriz de pesos de Queen podemos saber cuales son los poligonos vecinos para cualquier observación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen['E06000003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.neighbors['E06000003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.weights['E06000007']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ademas permite conocer la relación de vencindad entre dos observaciones específicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen['E06000003']['E07000164']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que el número de vecinos para cada observación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.cardinalities['E06000003']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conocer el número de vecinos para cada observación se puede obtener la siguiente tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_card = pd.Series(w_queen.cardinalities)\n",
    "queen_card.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para graficar una observación y sus vecinos utilizamos el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure\n",
    "f, ax = plt.subplots(1, figsize=(6, 6))\n",
    "# Plot base layer of polygons\n",
    "br.plot(ax=ax, facecolor='k', linewidth=0.1)\n",
    "# Select focal polygon\n",
    "# NOTE we pass both the area code and the column name\n",
    "#      (`geometry`) within brackets!!!\n",
    "focus = br.loc[['E06000007'], ['geometry']]\n",
    "# Plot focal polygon\n",
    "focus.plot(facecolor='red', alpha=1, linewidth=0, ax=ax)\n",
    "# Plot neighbors\n",
    "neis = br.loc[w_queen['E06000007'], :]\n",
    "neis.plot(ax=ax, facecolor='lime', linewidth=0)\n",
    "f.suptitle(\"Queen neighbors of `E06000007`\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.max_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.islands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda donde calculamos $W$ devolvió una advertencia sobre \"islas\". Recuerda que estas son islas no necesariamente en el sentido geográfico (aunque algunas lo serán), sino en el sentido matemático del término: autoridades locales que no comparten frontera con ninguna otra y, por lo tanto, no tienen vecinos. Podemos inspeccionar y mapearlas para tener una mejor idea de con qué estamos tratando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = br.plot(color='k', figsize=(9, 9))\n",
    "br.loc[w_queen.islands, :].plot(color='red', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, todas las islas son realmente \"islas\" en el sentido geográfico. Estos casos pueden crear problemas en el análisis y distorsionar los resultados. Hay varias soluciones a esta situación, como conectar las islas a otras observaciones a través de un criterio diferente (por ejemplo, el vecino más cercano), y luego combinar ambas matrices de pesos espaciales. Por conveniencia, las eliminaremos del conjunto de datos porque son una muestra pequeña y su eliminación probablemente no tendrá un gran impacto en los cálculos.eE este caso usaremos el comando `drop`, que es muy útil en estos casos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = br.drop(w_queen.islands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tengamos el conjunto de autoridades locales que no son islas, necesitamos volver a calcular la matriz de pesos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the spatial weights matrix\n",
    "w = weights.Queen.from_dataframe(br, idVariable='LAD14CD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, finalmente, vamos a estandarizar por filas para asegurarnos de que cada fila de la matriz sume uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row standardize the matrix\n",
    "w.transform = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahora, debido a que los hemos estandarizado por filas, el peso dado a cada uno de los cuatro vecinos es 0.2, lo que, en total, suma uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w['E08000012']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero no solamente existe tipo **Queens**. La designación de vecinos se puede identificar con una analogía de ajedrez: casos horizontales/verticales (**Rooks**), casos diagonales (**Bishops**) o en todos los casos (**Queens**) a lo largo de una cuadrícula regular. En polígonos irregulares, los vecinos tipo torre están conectados a lo largo de los bordes, los vecinos tipo **Bishops** por puntos, y los vecinos tipo **Queens** tanto por puntos como por bordes. Así que en este ejemplo, el vecindario establecido utilizando el caso de las **Queens** contiene ocho (8) vecinos, cuatro (4) vecinos por bordes en el caso de las **Rooks**, y cuatro (4) vecinos por puntos en el caso de los **Bishops**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/564x/ad/d9/78/add978b7eea6a8ec39e45be6beeea529.jpg\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de pesos basada en distancias\n",
    "\n",
    "Las matrices de pesos basadas en la distancia asignan los pesos de acuerdo con dicha distancia. Es importante para este tipo de análisis contar con los datos proyectados a un sistema de coordenadas planas y no geográfico, de tal forma que permita medir distancias. Para este caso se debe reproyectar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/564x/ed/a9/6c/eda96cea5c70aab018bf6fe326f4a540.jpg\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imd=br.to_crs(epsg=27700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del método de vecino mas cercano (KNN) se debe ingresar como argumento el número de vecinos a considerar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5 = weights.KNN.from_dataframe(imd, k=5)\n",
    "knn5['E06000007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5.weights['E06000007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5.neighbors['E06000007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn5_card = pd.Series(knn5.cardinalities)\n",
    "knn5_card.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de hacerlo es identificar manualmente el centroide de cada poligono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cents = imd.centroid\n",
    "pts = np.array([(pt.x, pt.y) for pt in cents]) # Extract coordinates into an array\n",
    "knn5_from_pts = weights.KNN.from_array(pts, k=5) # Compute KNN weights\n",
    "knn5_from_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conocer el número de vecinos en una distancia dada se utiliza el método de Bandas, donde a cada observación dentro del rango establecido se le asigna un peso igual al inverso de la distancia:\n",
    "\n",
    "$$\n",
    "w_{ij} = \\dfrac{1}{d_{ij}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist50kmB = weights.DistanceBand.from_dataframe(imd, 50000)\n",
    "w_dist50kmB['E06000007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dist50kmC = weights.DistanceBand.from_dataframe(imd, 50000, binary=False)\n",
    "w_dist50kmC['E06000007']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma grafica del anterior análisis se puede ejecutar de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "# Plot base layer of polygons\n",
    "imd.plot(ax=ax, facecolor='k', linewidth=0.1)\n",
    "# Select focal polygon\n",
    "# NOTE we pass both the area code and the column name\n",
    "#      (`geometry`) within brackets!!!\n",
    "focus = imd.loc[['E06000007'], ['geometry']]\n",
    "# Plot focal polygon\n",
    "focus.plot(facecolor='red', alpha=1, linewidth=0, ax=ax)\n",
    "# Plot neighbors\n",
    "neis = imd.loc[w_dist50kmC['E06000007'], :]\n",
    "neis.plot(ax=ax, facecolor='lime', linewidth=0)\n",
    "# Plot 1km buffer\n",
    "buf = focus.centroid.buffer(50000)\n",
    "buf.plot(edgecolor='red', facecolor='none', ax=ax, linewidth=4)\n",
    "# Plot centroids of neighbor\n",
    "pts = np.array([(pt.x, pt.y) for pt in imd.centroid])\n",
    "ax.plot(pts[:, 0], pts[:, 1], color='#00d8ea', \n",
    "        linewidth=0, alpha=0.75, marker='o', markersize=4)\n",
    "# Title\n",
    "f.suptitle(\"Neighbors within 1km of `E06000007`\")\n",
    "# Style, zoom and display on screen\n",
    "#ax.set_ylim(388000, 393500)\n",
    "#ax.set_xlim(336000, 339500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial lag\n",
    "\n",
    "El *spatial lag* de una variable es el producto de la matriz de pesos con la variable misma.\n",
    "\n",
    "$$\n",
    "Y_{sl} = W Y\n",
    "$$\n",
    " \n",
    "Donde 𝑌  es un vector Nx1 con los valores de la variable.\n",
    "\n",
    "$$\n",
    "y_{sl-i} = \\displaystyle \\sum_j w_{ij} y_j\n",
    "$$\n",
    "\n",
    "Una vez que tengamos los datos y la matriz de pesos espaciales listos, podemos comenzar calculando el retraso espacial del porcentaje de votos que se emitieron para salir de la UE. Recuerda que el retraso espacial es el producto de la matriz de pesos espaciales y una variable dada, y que si $W$ está estandarizado por filas, el resultado equivale al valor promedio de la variable en el vecindario de cada observación.\n",
    "\n",
    "Podemos calcular el *spatial lag* para la variable `Pct_Leave` y almacenarlo directamente en la tabla principal con la siguiente línea de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['w_Pct_Leave'] = weights.lag_spatial(w, br['Pct_Leave'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demos un vistazo rápido a la variable resultante, en comparación con la original:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br[['LAD14NM', 'Pct_Leave', 'w_Pct_Leave']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de interpretar el retraso espacial (`w_Pct_Leave`) para, por ejemplo, la primera observación, es la siguiente: Hartlepool, donde el 69,6% del electorado votó para salir, está rodeado por autoridades locales vecinas donde, en promedio, casi el 62% del electorado también votó para salir de la UE. Para fines de ilustración, de hecho podemos verificar que esto es correcto consultando la matriz de pesos espaciales para averiguar los vecinos de Hartepool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.neighbors['E06000001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los valores de las expectativas teóricas para cada tipo de unión:57\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neis = br.loc[w.neighbors['E06000001'], 'Pct_Leave']\n",
    "neis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el valor promedio, que vimos en el retraso espacial como 61.8, se puede calcular de la siguiente manera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neis.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comparar fácilmente diferentes gráficos de dispersión y detectar observaciones atípicas, es práctica común estandarizar los valores de la variable antes de calcular su retraso espacial y representarlo. Esto se puede lograr restando el valor promedio y dividiendo el resultado por la desviación estándar:\n",
    "\n",
    "$\n",
    "z_i = \\frac{y - \\bar{y}}{\\sigma_y}\n",
    "$\n",
    "\n",
    "Estandarizar significa restar el valor promedio y dividir por la desviación estándar cada observación de la columna. Esto se puede hacer fácilmente con un poco de álgebra básica en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['Pct_Leave_std'] = (br['Pct_Leave'] - br['Pct_Leave'].mean()) / br['Pct_Leave'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, para poder explorar los patrones espaciales de los valores estandarizados, a veces también llamados valores $z$, necesitamos crear su retraso espacial:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['w_Pct_Leave_std'] = weights.lag_spatial(w, br['Pct_Leave_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1, ax2 = axs\n",
    "br.plot(column='Pct_Leave', cmap='viridis', scheme='quantiles',k=5, edgecolor='white', linewidth=0., alpha=0.75, legend=True, ax=ax1)\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title(\"% Leave\")\n",
    "ctx.add_basemap(ax1,crs=br.crs,source=ctx.providers.Stamen.TerrainBackground)\n",
    "br.plot(column='w_Pct_Leave', cmap='viridis', scheme='quantiles',k=5, edgecolor='white', linewidth=0., alpha=0.75, legend=True, ax=ax2)\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title(\"% Leave - Spatial Lag\")\n",
    "ctx.add_basemap(ax2,crs=br.crs,source=ctx.providers.Stamen.TerrainBackground,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las marcadas diferencias a la izquierda entre vecinos inmediatos (como en el caso de Liverpool, en el noroeste de Inglaterra) se atenúan en el mapa de la derecha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelación espacial global\n",
    "\n",
    "El mapa anterior es una buena manera de comenzar a explorar los principales patrones espaciales en los datos. A primera vista, parece mostrar una cantidad considerable de autocorrelación espacial positiva: las autoridades locales con altos porcentajes de votos para salir de la UE tienden a estar cerca unas de otras (ver, por ejemplo, la región oriental), al igual que aquellas donde una proporción mucho menor de su población votó para salir (con Escocia siendo un buen ejemplo en el norte). Sin embargo, los humanos son muy buenos detectores de patrones. A lo largo de nuestra historia desde que empezamos como especie, la vida ha recompensado las habilidades de reconocimiento de patrones y ha castigado a los individuos que carecen de ellas. Piensa en la ventaja que tenían nuestros ancestros si podían detectar formas o movimientos particulares mientras cazaban, o en los problemas en los que podían meterse si no eran capaces de reconocer a ciertos otros en la oscuridad de la noche en la selva. Esta extraordinaria capacidad para detectar tendencias, patrones y asociaciones también tiende a crear muchos falsos positivos: casos en los que pensamos que hay un patrón pero, de hecho, lo que estamos viendo es en gran medida aleatorio. Esto se acentúa particularmente en el caso de los mapas donde, la forma de las geometrías también puede distorsionar significativamente nuestra percepción. Al observar el mapa anterior, por ejemplo, podemos hacer una suposición educada sobre la presencia de autocorrelación espacial; pero en realidad determinar si lo que estamos viendo podría haber ocurrido por pura casualidad o no suele ser más fácil decirlo que hacerlo.\n",
    "\n",
    "Ese es exactamente el propósito de los indicadores de autocorrelación espacial global: aprovechar el poder de la estadística para ayudarnos primero a resumir la distribución espacial de los valores presentes en un mapa, y segundo obtener una cuantificación formal de la desviación de la aleatoriedad. Las estadísticas diseñadas para medir esta tendencia caracterizan así un mapa en términos de su grado de agrupamiento y lo resumen, ya sea de manera visual o numérica. Sin embargo, antes de que podamos sumergirnos en las estadísticas, necesitamos entender un bloque de construcción fundamental: *spatial lag*. Con ese concepto estamos en posición de construir una buena comprensión de la autocorrelación espacial global. Entraremos suavemente en ella con el caso binario, cuando las observaciones solo pueden tomar dos valores (potencialmente categóricos), antes de cubrir los dos del caso continuo: el Gráfico de Moran y el Índice de Moran (Moran's I).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso binario: conteos de unión\n",
    "\n",
    "El retraso espacial juega un papel importante en la cuantificación de la autocorrelación espacial. Usándolo, podemos comenzar a relacionar el comportamiento de una variable en una ubicación dada con su patrón en el vecindario inmediato. Las medidas de autocorrelación espacial global luego usarán cada observación para construir medidas generales sobre la tendencia general en un conjunto de datos dado.\n",
    "\n",
    "Nuestra primera incursión en estas medidas considera un caso simplificado: valores binarios. Esto ocurre cuando la variable en la que estamos interesados solo toma dos valores. En este contexto, estamos interesados en saber si una observación dada está rodeada por otras dentro de la misma categoría. Por ejemplo, volviendo a nuestro conjunto de datos, queremos evaluar en qué medida las autoridades locales que votaron para salir tienden a estar rodeadas por otras que también votaron para salir. Para proceder, primero calculemos una variable binaria (Leave) que indique 1 si la autoridad local votó para salir, y cero en caso contrario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['Leave'] = (br['Pct_Leave'] > 50).astype(int)\n",
    "br[['Pct_Leave', 'Leave']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo cual podemos visualizar fácilmente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "br.plot(ax=ax, column='Leave', categorical=True, legend=True, \n",
    "        edgecolor='0.5', linewidth=0.25, cmap='Set3', \n",
    "        figsize=(9, 9));\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Leave Majority')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visiblemente, parece que el mapa representa un claro caso de autocorrelación espacial positiva: en general, hay pocos casos visibles donde una observación dada está rodeada por otras en la categoría opuesta. Para explorar formalmente esta evaluación inicial, podemos usar lo que se llama una estadística de \"conteo de unión\". Imagina un tablero de ajedrez con cuadrados verdes (G, valor 0) y amarillos (Y, valor 1). La idea de la estadística es contar las ocurrencias de uniones (o pares de vecinos) verdes-verdes (GG), amarillo-amarillo (YY), o verde-amarillo/amarillo-verde (GY) en el mapa. En este contexto, tanto GG como YY reflejan autocorrelación espacial positiva, mientras que GY captura su contraparte negativa. La intuición de la estadística es proporcionar una línea de base de cuántos GG, YY y GY se esperaría bajo el caso de completa aleatoriedad espacial, y comparar esto con los recuentos observados en el conjunto de datos. Una situación donde observamos más GG/YY de lo esperado y menos GY de lo esperado sugeriría autocorrelación espacial positiva; mientras que lo opuesto, más GY que GG/YY, apuntaría hacia autocorrelación espacial negativa.\n",
    "\n",
    "Dado que los pesos espaciales solo se usan aquí para delimitar quién es vecino o no, la estadística de conteo de unión requiere pesos binarios. Así que transformemos w de vuelta a un estado no estandarizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.transform = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular la estadística como:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc = esda.join_counts.Join_Counts(br['Leave'], w)\n",
    "jc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es común en todo PySAL, estamos creando un objeto (jc) que contiene mucha información más allá del valor de la estadística calculada. Por ejemplo, podemos verificar cuántas ocurrencias de GG tenemos (nota el atributo es bb, que proviene de la referencia original donde las dos clases consideradas eran negras y blancas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántas ocurrencias de YY tiene nuestro mapa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.ww"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y cuántas GY/YG encontramos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suma de estos tres nos da el número total de comparaciones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bb + jc.ww + jc.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estadística se basa en comparar el número real de uniones de cada clase (bb, ww, bc) con lo que uno esperaría en un caso de aleatoriedad espacial. Esas expectativas también se pueden acceder, para el caso de GG/YY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.mean_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for GY joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.mean_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inferencia estadística para obtener una idea de si estos valores probablemente provienen del azar o no se puede obtener como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.p_sim_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.p_sim_bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados apuntan a una clara presencia de autocorrelación espacial positiva, ya que hay muchas más uniones de pares en la misma categoría de las que se esperaría (p_sim_bb) y significativamente menos uniones de categorías opuestas (p_sim_bw)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de Moran\n",
    "\n",
    "El gráfico de Moran es una forma de visualizar un conjunto de datos espaciales para explorar la naturaleza y la fuerza de la autocorrelación espacial. Esencialmente, es un gráfico de dispersión tradicional en el que la variable de interés se muestra contra su retraso espacial. Para poder interpretar los valores como por encima o por debajo de la media, y sus cantidades en términos de desviaciones estándar, la variable de interés suele estandarizarse restando su media y dividiéndola por su desviación estándar.\n",
    "\n",
    "Técnicamente hablando, crear un Gráfico de Moran es muy similar a crear cualquier otro gráfico de dispersión en Python, siempre que hayamos estandarizado la variable y calculado su retraso espacial de antemano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['Pct_Leave_std'] = ( br['Pct_Leave'] - br['Pct_Leave'].mean() )/ br['Pct_Leave'].std()\n",
    "br['Pct_Leave_lag_std'] = ( br['w_Pct_Leave_std'] - br['w_Pct_Leave_std'].mean() )/ br['w_Pct_Leave_std'].std()\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(6, 6))\n",
    "sns.regplot(x='Pct_Leave_std', y='w_Pct_Leave_std',ci=None, data=br, line_kws={'color':'r'})\n",
    "ax.axvline(0, c='k', alpha=0.5)\n",
    "ax.axhline(0, c='k', alpha=0.5)\n",
    "ax.set_title('Moran Plot - % Leave')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de obtener esta gráfica es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot values\n",
    "sns.regplot(x='Pct_Leave_std', y='w_Pct_Leave_std', data=br, ci=None)\n",
    "# Add vertical and horizontal lines\n",
    "plt.axvline(0, c='k', alpha=0.5)\n",
    "plt.axhline(0, c='k', alpha=0.5)\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figura anterior muestra la relación entre el porcentaje estandarizado que votó para salir de la UE (`Pct_Leave_std`) y su retraso espacial que, debido a que el $W$ que se utilizó está estandarizado por filas, puede interpretarse como el porcentaje promedio que votó para salir en las áreas circundantes de una Autoridad Local dada. Para guiar la interpretación del gráfico, también se incluye un ajuste lineal en la publicación. Esta línea representa el mejor ajuste lineal al gráfico de dispersión o, en otras palabras, la mejor manera de representar la relación entre las dos variables como una línea recta.\n",
    "\n",
    "El gráfico muestra una relación positiva entre ambas variables. Esto se asocia con la presencia de autocorrelación espacial *positiva*: valores similares tienden a estar ubicados cerca uno del otro. Esto significa que la *tendencia general* es que los valores altos estén cerca de otros valores altos, y que los valores bajos estén rodeados de otros valores bajos. Sin embargo, esto no significa que esta sea la única situación en el conjunto de datos: por supuesto, puede haber casos particulares donde los valores altos estén rodeados de valores bajos, y viceversa. Pero significa que, si tuviéramos que resumir el patrón principal de los datos en términos de cuán agrupados están los valores similares, la mejor manera sería decir que están positivamente correlacionados y, por lo tanto, agrupados en el espacio.\n",
    "\n",
    "En el contexto del ejemplo, esto se puede interpretar en el sentido de que: las autoridades locales muestran autocorrelación espacial positiva en la forma en que votaron en el referéndum de la UE. Esto significa que las autoridades locales con un alto porcentaje de votantes a favor de salir tienden a estar ubicadas cerca de otras autoridades locales donde también una parte significativa del electorado votó para salir, y viceversa.\n",
    "\n",
    "El Gráfico de Moran es una excelente herramienta para explorar los datos y tener una buena idea de cuánto están agrupados los valores en el espacio. Sin embargo, debido a que es un dispositivo gráfico, a veces es difícil condensar sus ideas en una forma más concisa. Para estos casos, un buen enfoque es idear una medida estadística que resuma la figura. Esto es exactamente para lo que está destinado el Índice de Moran.\n",
    "\n",
    "De la misma manera que la media resume un elemento crucial de la distribución de valores en un entorno no espacial, el Índice de Moran hace lo mismo para un conjunto de datos espaciales. Continuando con la comparación, podemos pensar en la media como un único valor numérico que resume un histograma o un gráfico de densidad de núcleo. De manera similar, el Índice de Moran captura gran parte de la esencia del Gráfico de Moran. De hecho, hay una conexión aún más cercana entre los dos: el valor del Índice de Moran corresponde con la pendiente de la ajuste lineal superpuesto en el Gráfico de Moran.\n",
    "\n",
    "Para calcular el Índice de Moran en nuestro conjunto de datos, podemos llamar a una función específica en `PySAL` directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = esda.Moran(br['Pct_Leave'], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta cómo no necesitamos utilizar la versión estandarizada en este contexto, ya que no la representaremos visualmente.\n",
    "\n",
    "El método `ps.Moran` crea un objeto que contiene mucha más información que la estadística real. Si queremos recuperar el valor de la estadística, podemos hacerlo de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La otra información que extraeremos del Índice de Moran se relaciona con la inferencia estadística: ¿qué tan probable es que el patrón que observamos en el mapa y que captura en su valor el Índice de Moran sea generado por un proceso completamente aleatorio? Si consideráramos la misma variable pero reorganizáramos sus ubicaciones al azar, ¿obtendríamos un mapa con características similares?\n",
    "\n",
    "Los detalles específicos del mecanismo para calcular esto están más allá del alcance de la sesión, pero es importante saber que un valor p lo suficientemente pequeño asociado con el Índice de Moran de un mapa permite rechazar la hipótesis de que el mapa es aleatorio. En otras palabras, podemos concluir que el mapa muestra más patrón espacial de lo que esperaríamos si los valores se hubieran asignado aleatoriamente a una ubicación particular.\n",
    "\n",
    "El valor p más confiable para el Índice de Moran se puede encontrar en el atributo `p_sim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor se calcula como un valor p empírico que representa la proporción de realizaciones en la simulación bajo aleatoriedad espacial que son más extremas que el valor observado. Un valor p lo suficientemente pequeño asociado con el Índice de Moran de un mapa permite rechazar la hipótesis de que el mapa es aleatorio. En otras palabras, podemos concluir que el mapa muestra más patrón espacial de lo que esperaríamos si los valores se hubieran asignado aleatoriamente a ubicaciones.\n",
    "\n",
    "Ese es un valor muy bajo, especialmente considerando que en realidad es el valor mínimo que podríamos haber obtenido dado que la simulación detrás de él utilizó 999 permutaciones (el valor predeterminado en PySAL) y, en términos estándar, se consideraría estadísticamente significativo. Podemos elaborar un poco más sobre la intuición detrás del valor de p_sim. Si generamos un gran número de mapas con los mismos valores pero distribuidos aleatoriamente en el espacio, y calculamos la estadística del Índice de Moran para cada uno de esos mapas, solo el 0.01% de ellos mostraría un valor absoluto más grande que el que obtenemos a partir de los datos observados, y el otro 99.99% de los mapas aleatorios recibirían un valor absoluto más pequeño del Índice de Moran. Si recordamos nuevamente que el valor del Índice de Moran también se puede interpretar como la pendiente del Gráfico de Moran, lo que tenemos es que, en este caso, la disposición espacial particular de valores sobre el espacio que observamos para el porcentaje de votos a Favor de salir es más concentrada que si mezcláramos aleatoriamente las proporciones de votos en el mapa, de ahí la significación estadística. Como primer paso, el análisis de autocorrelación global puede enseñarnos que las observaciones parecen estar positivamente autocorrelacionadas en el espacio. De hecho, el patrón espacial general en la votación del Referéndum de la UE fue muy marcado: las áreas cercanas tendían a votar de manera similar.\n",
    "\n",
    "Gracias al módulo de visualización splot en PySAL, podemos obtener una representación rápida de la estadística que combina el Gráfico de Moran (derecha) con un gráfico de la prueba empírica que llevamos a cabo para obtener p_sim (izquierda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.viz import splot\n",
    "from splot.esda import plot_moran\n",
    "plot_moran(mi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el panel izquierdo podemos ver en gris la distribución empírica generada al simular 999 mapas aleatorios con los valores de la variable Pct_Leave y luego calcular el Índice de Moran para cada uno de esos mapas. La línea azul señala la media. Por el contrario, la línea roja muestra el Índice de Moran calculado para la variable utilizando la geografía observada en el conjunto de datos. Es claro que el valor bajo el patrón observado es significativamente más alto que bajo la aleatoriedad. Esta percepción se confirma en el panel derecho, donde se muestra un gráfico equivalente al Gráfico de Moran que creamos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelación espacial local\n",
    "\n",
    "En el capítulo anterior exploramos el uso de medidas globales de autocorrelación espacial para plantear la pregunta de si la distribución espacial general de nuestro atributo de interés reflejaba un proceso geográficamente aleatorio o no. Estas estadísticas son útiles ya que la presencia de autocorrelación espacial tiene importantes implicaciones para el análisis estadístico posterior. Desde una perspectiva sustantiva, la autocorrelación espacial podría reflejar la operación de procesos que generan asociación entre los valores en ubicaciones cercanas. En estos casos, el modelado formal de las dimensiones espaciales de los procesos debería llevarse a cabo a continuación. Por otro lado, la autocorrelación espacial a veces puede surgir de operaciones de procesamiento de datos en las que los casos de dependencia son una forma de ruido no aleatorio en lugar de debido a procesos sustantivos. Independientemente de si la autocorrelación espacial se debe a fuentes sustantivas o de molestias, es una forma de no aleatoriedad que complica el análisis estadístico.\n",
    "\n",
    "Por estas razones, la capacidad de determinar si la autocorrelación espacial está presente en un conjunto de datos georreferenciados es un componente crítico del conjunto de herramientas de ciencia de datos espaciales. Dicho esto, las medidas globales de autocorrelación espacial son estadísticas de \"mapa completo\", lo que significa que la única estadística se refiere al conjunto completo de datos. En otras palabras, las estadísticas globales de autocorrelación nos permiten detectar agrupaciones en un conjunto de datos georreferenciado. Por ejemplo, Moran's I es una buena herramienta para resumir un conjunto de datos en un único valor que informa sobre su grado de agrupamiento geográfico. Sin embargo, no es una medida adecuada para identificar áreas dentro del mapa donde se encuentran tipos específicos de valores (por ejemplo, altos, bajos). En otras palabras, Moran's I nos puede decir que los valores están agrupados en general, pero no nos informará sobre dónde están los grupos. Para ese propósito, necesitamos usar una medida local de autocorrelación espacial. Las medidas locales consideran cada observación individual y operan sobre ellas, en contraposición al conjunto de datos en su conjunto, como lo hacen las medidas globales. Debido a eso, no son buenas para resumir un mapa, pero permiten obtener más información sobre subconjuntos geográficos interesantes de los datos. En este capítulo, consideramos los Indicadores Locales de Asociación Espacial (LISAs), un contraparte local de medidas globales como Moran's I. En el núcleo de este método hay una clasificación de las observaciones en un conjunto de datos en cuatro grupos derivados del Gráfico de Moran: valores altos rodeados de valores altos (HH), valores bajos cerca de otros valores bajos (LL), valores altos entre valores bajos (HL), y viceversa (LH). Cada uno de estos grupos se llama típicamente \"cuadrantes\". Se puede ver una ilustración de dónde cae cada uno de estos grupos en el Gráfico de Moran a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot values\n",
    "sns.regplot(x='Pct_Leave_std', y='w_Pct_Leave_std', data=br, ci=None)\n",
    "# Add vertical and horizontal lines\n",
    "plt.axvline(0, c='k', alpha=0.5)\n",
    "plt.axhline(0, c='k', alpha=0.5)\n",
    "plt.text(1.75, 0.5, \"HH\", fontsize=25)\n",
    "plt.text(1.5, -1.5, \"HL\", fontsize=25)\n",
    "plt.text(-2, 1, \"LH\", fontsize=25)\n",
    "plt.text(-1.5, -2.5, \"LL\", fontsize=25)\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos clasificado cada observación en el conjunto de datos según su valor y el de sus vecinos. Esto es solo la mitad del camino para identificar áreas de concentración inusual de valores. Para saber si cada una de las ubicaciones es un cluster *estadísticamente significativo* de un tipo dado, nuevamente necesitamos compararlo con lo que esperaríamos si los datos se asignaran de manera completamente aleatoria. Después de todo, por definición, cada observación será de un tipo u otro, según la comparación anterior. Sin embargo, lo que nos interesa es si la fuerza con la que los valores están concentrados es inusualmente alta.\n",
    "\n",
    "Esto es exactamente para lo que están diseñados los LISAs. Como antes, una descripción más detallada de sus fundamentos estadísticos está fuera del alcance en este contexto, pero trataremos de arrojar algo de luz sobre la intuición de cómo lo hacen. La idea central es identificar casos en los que la comparación entre el valor de una observación y el promedio de sus vecinos sea más similar (HH, LL) o más diferente (HL, LH) de lo que esperaríamos por pura casualidad. El mecanismo para hacer esto es similar al del Moran's I global, pero aplicado en este caso a cada observación, lo que resulta en tantas estadísticas como observaciones originales.\n",
    "\n",
    "De esta forma la gráfica de Moran queda centrada en el plot, partiendo el espacio en cuadrantes que representan:\n",
    "\n",
    "- High-High (HH): valores por encima de la media rodeado por valores por encima de la media.\n",
    "- Low-Low (LL): valores por debajo de la media rodeado por valores por debajo de la media.\n",
    "- High-Low (HL): valores por encima de la media rodeado por valores por debajo de la media.\n",
    "- Low-High (LH): valores por debajo de la media rodeado por valores por encima de la media.\n",
    "\n",
    "Los LISAs se utilizan ampliamente en muchos campos para identificar clusters de valores en el espacio. Son una herramienta muy útil que puede devolver rápidamente áreas en las que los valores están concentrados y proporcionar evidencia *sugerente* sobre los procesos que podrían estar en juego. Por eso, tienen un lugar privilegiado en la caja de herramientas exploratoria. Ejemplos de contextos donde los LISAs pueden ser útiles incluyen: identificación de clusters espaciales de pobreza en regiones, detección de enclaves étnicos, delimitación de áreas de actividad particularmente alta/baja de cualquier fenómeno, etc.\n",
    "\n",
    "En Python, podemos calcular LISAs de una manera muy simplificada gracias a `PySAL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa = esda.Moran_Local(br['Pct_Leave'], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto revela una distribución bastante sesgada debido al predominio de las formas positivas de asociación espacial. Aquí es importante tener en cuenta que los valores positivos altos surgen de la similitud de valores en el espacio, y esto puede deberse a que los valores altos están al lado de valores altos o a que los valores bajos están al lado de valores bajos. Los valores locales Ii en sí mismos no pueden distinguir entre estos dos casos.\n",
    "\n",
    "Los valores en la cola izquierda de la densidad representan ubicaciones que muestran asociación espacial negativa. También hay dos formas, un valor alto rodeado de valores bajos, o un valor bajo rodeado de observaciones vecinas de alto valor. Y, nuevamente, el valor Ii no puede distinguir entre los dos casos.\n",
    "\n",
    "Debido a su propia naturaleza, mirar el resultado numérico de los LISAs no siempre es la forma más útil de aprovechar toda la información que pueden proporcionar. Recuerda que estamos calculando una estadística para cada observación en los datos, por lo que, si tenemos muchas de ellas, será difícil extraer algún patrón significativo. En este contexto, un mapa de coropletas puede ayudar. A primera vista, esto puede parecer sugerir que un mapa de los valores Ii sería una forma útil de visualizar la distribución espacial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9,9))\n",
    "br['Is'] = lisa.Is\n",
    "br.plot(column='Is', cmap='viridis', scheme='quantiles',k=5, edgecolor='white', linewidth=0.1, alpha=0.75, legend=True,ax=ax);\n",
    "ctx.add_basemap(ax,crs=br.crs,source=ctx.providers.Stamen.TerrainBackground)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, esto no nos informa de ninguna manera sobre qué tipo de correlación espacial está experimentando cada área. Por ejemplo, ¿son similares las áreas amarillas en Escocia a las del clúster oriental de valores altos también? Además, sabemos que los valores alrededor de cero no serán estadísticamente significativos. ¿Cuáles son, por lo tanto, significativos y no significativos desde un punto de vista estadístico? En otras palabras, ¿cuáles pueden considerarse clústeres estadísticos y cuáles ruido? Para responder a estas preguntas, necesitamos traer información adicional que hemos obtenido al calcular las estadísticas LISA. Primero construyamos una figura de cuatro parcelas que reúna todas estas perspectivas diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "# Set up figure and axes\n",
    "f, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "# Make the axes accessible with single indexing\n",
    "axs = axs.flatten()\n",
    "\n",
    "                    # Subplot 1 #\n",
    "ax = axs[0]\n",
    "br.plot(column='Is', cmap='viridis', scheme='quantiles',\n",
    "        k=5, edgecolor='white', linewidth=0.1, alpha=0.75, legend=True, ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "                    # Subplot 2 #\n",
    "ax = axs[1]\n",
    "q_labels = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "labels = [q_labels[i-1] for i in lisa.q]\n",
    "hmap = ListedColormap([ 'red', 'lightblue', 'blue', 'pink'])\n",
    "br.assign(cl=labels).plot(column='cl', categorical=True, \\\n",
    "        k=2, cmap=hmap, linewidth=0.1, ax=ax, \\\n",
    "        edgecolor='white', legend=True)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "                    # Subplot 3 #\n",
    "\n",
    "ax = axs[2]\n",
    "sig = 1 * (lisa.p_sim < 0.05)\n",
    "hmap = ListedColormap(['grey','black'])\n",
    "labels = ['non-sig.', 'significant'] \n",
    "labels = [labels[i] for i in sig]\n",
    "br.assign(cl=labels).plot(column='cl', categorical=True, \\\n",
    "        k=2, cmap=hmap, linewidth=0.1, ax=ax, \\\n",
    "        edgecolor='white', legend=True)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "                            \n",
    "                    # Subplot 4 #\n",
    "ax = axs[3]\n",
    "hotspot = 1 * (sig * lisa.q==1)\n",
    "coldspot = 3 * (sig * lisa.q==3)\n",
    "doughnut = 2 * (sig * lisa.q==2)\n",
    "diamond = 4 * (sig * lisa.q==4)\n",
    "spots = hotspot + coldspot + doughnut + diamond\n",
    "spot_labels = [ '0 ns', '1 hot spot', '2 doughnut', '3 cold spot', '4 diamond']\n",
    "labels = [spot_labels[i] for i in spots]\n",
    "hmap = ListedColormap([ 'grey', 'red', 'lightblue', 'blue', 'pink'])\n",
    "\n",
    "\n",
    "br.assign(cl=labels).plot(column='cl', categorical=True, \\\n",
    "        k=2, cmap=hmap, linewidth=0.1, ax=ax, \\\n",
    "        edgecolor='white', legend=True)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figura en la parte superior izquierda replica nuestro primer mapa anterior. Las ubicaciones verdes y amarillas tienen los valores más grandes para las estadísticas locales, sin embargo, esto no distingue entre asociación positiva de bajo apoyo para el voto Brexit y asociación positiva de alto apoyo para el Brexit.\n",
    "\n",
    "Para distinguir entre estos dos casos, el mapa en la parte superior derecha muestra la ubicación de la estadística LISA en el cuadrante del gráfico de dispersión de Moran, que se registra en el atributo q:\n",
    "\n",
    "Todo lo que necesitamos pasar es la variable de interés, el porcentaje de votos para salir, y los pesos espaciales que describen las relaciones de vecindad entre las diferentes observaciones que componen el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break observations into significant or not\n",
    "br['significant'] = lisa.p_sim < 0.05\n",
    "# Store the quadrant they belong to\n",
    "br['quadrant'] = lisa.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detengámonos un momento en estos dos pasos. Primero, la columna `significant`. De manera similar al Moran's I global, `PySAL` está calculando automáticamente un valor p para cada LISA. Dado que no todas las observaciones representan una situación estadísticamente significativa, queremos identificar aquellas con un valor p lo suficientemente pequeño como para descartar la posibilidad de obtener una situación similar por pura casualidad. Siguiendo un razonamiento similar al del Moran's I global, seleccionamos el 5% como el umbral para la significancia estadística. Para identificar estos valores, creamos una variable, `significant`, que contiene `True` si el valor p de la observación satisface la condición, y `False` en caso contrario. Podemos verificar si esto es así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['significant'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota cómo el tercero y el cuarto son menores que 0.05, como la variable `significant` identificó correctamente.\n",
    "\n",
    "En segundo lugar, el cuadrante al que pertenece cada observación. Este es más fácil ya que viene incorporado directamente en el objeto `lisa`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br['quadrant'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correspondencia entre los números en la variable y los cuadrantes reales es la siguiente:\n",
    "\n",
    "* 1: HH\n",
    "* 2: LH\n",
    "* 3: LL\n",
    "* 4: HL\n",
    "\n",
    "Con estos dos elementos, `significant` y `quadrant`, podemos construir un mapa típico de clúster LISA, combinando las habilidades de mapeo con lo que hemos aprendido sobre cómo hacer subconjuntos y consultas en tablas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import lisa_cluster\n",
    "lisa_cluster(lisa, br);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mapa anterior muestra los resultados de LISA del voto del Brexit. En rojo brillante, encontramos aquellas autoridades locales con una concentración inusual de votantes partidarios de dejar la UE, rodeados también por niveles altos de voto a favor de dejar. Esto corresponde con áreas en el este de Inglaterra, el Black Country y el este de Londres. En rojo claro, encontramos el primer tipo de *valores atípicos espaciales*. Estas son áreas con un alto voto a favor de dejar, pero rodeadas de áreas con poco apoyo para dejar la UE (por ejemplo, el centro de Londres). Finalmente, en azul claro encontramos el otro tipo de valor atípico espacial: autoridades locales con bajo apoyo para dejar, rodeadas de otras autoridades con alto apoyo.\n",
    "\n",
    "La interpretación sustantiva de un mapa LISA debe relacionar su resultado con la intención original del analista que creó el mapa. En este caso, nuestra idea original era explorar la estructura espacial del apoyo para salir de la UE. El LISA resulta ser una herramienta bastante útil en este contexto. Comparando el mapa LISA anterior con el coroplético con el que comenzamos, podemos interpretar el LISA como una \"simplificación\" de la imagen detallada pero quizás demasiado complicada en el coroplético que enfoca la atención del lector en las áreas que muestran una concentración particularmente alta de valores (dis)similares, ayudando a que la estructura espacial del voto emerja de manera más explícita. El resultado de esto destaca la relevancia que tuvieron el este de Inglaterra y las Midlands en la votación para salir, así como las regiones del mapa donde hubo mucho menos entusiasmo por salir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(lisa, br, 'Pct_Leave');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}